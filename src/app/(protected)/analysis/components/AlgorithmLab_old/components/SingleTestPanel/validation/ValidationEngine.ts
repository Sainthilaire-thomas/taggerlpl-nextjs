// ValidationEngine.ts - Moteur de validation scientifique pour algorithmes
import { ValidationPair } from "../data/TurnTaggedDataProcessor";

// Types pour la validation
export interface AlgorithmPrediction {
  id: number;
  inputVerbatim: string;
  predictedStrategy?: string; // Classification strat√©gie conseiller
  predictedReaction: string; // Pr√©diction r√©action client
  confidence: number;
  algorithmUsed: string;
}

export interface ValidationMetrics {
  accuracy: number;
  precision: Record<string, number>;
  recall: Record<string, number>;
  f1Score: Record<string, number>;
  kappaCohen: number;
  support: Record<string, number>;
  confusionMatrix: number[][];
  classLabels: string[];
}

export interface ClassificationValidationResult {
  testType: "classification";
  algorithmName: string;
  sampleSize: number;
  overallMetrics: ValidationMetrics;
  byFamily: Record<string, ValidationMetrics>;
  discrepancies: DiscrepancyItem[];
  recommendations: string[];
}

export interface PredictionValidationResult {
  testType: "prediction";
  algorithmName: string;
  sampleSize: number;
  overallMetrics: ValidationMetrics;
  byStrategy: Record<string, ValidationMetrics>;
  discrepancies: DiscrepancyItem[];
  recommendations: string[];
}

export interface DiscrepancyItem {
  id: number;
  inputVerbatim: string;
  predicted: string;
  actual: string;
  confidence: number;
  discrepancyType: "false_positive" | "false_negative" | "misclassification";
  context: {
    strategy?: string;
    family?: string;
    callId: string;
  };
}

export interface DualValidationResult {
  classification: ClassificationValidationResult;
  prediction: PredictionValidationResult;
  crossAnalysis: {
    strategiesWithBestPrediction: Array<{ strategy: string; f1Score: number }>;
    reactionsHardestToPredict: Array<{ reaction: string; f1Score: number }>;
    correlationClassificationVsPrediction: number;
  };
  summary: {
    overallClassificationAccuracy: number;
    overallPredictionAccuracy: number;
    recommendedUseCase: string;
    confidenceReliability: number;
  };
}

export default class ValidationEngine {
  /**
   * Test 1: Validation accord de classification
   * V√©rifie si l'algorithme classe les verbatims dans les bonnes familles/strat√©gies
   */
  async validateClassificationAccuracy(
    predictions: AlgorithmPrediction[],
    goldStandard: ValidationPair[],
    algorithmName: string
  ): Promise<ClassificationValidationResult> {
    if (predictions.length !== goldStandard.length) {
      throw new Error("Taille diff√©rente entre pr√©dictions et gold standard");
    }

    // V√©rifier que les pr√©dictions de strat√©gie existent
    const hasStrategyPredictions = predictions.some(
      (p) => p.predictedStrategy !== undefined && p.predictedStrategy !== null
    );
    if (!hasStrategyPredictions) {
      console.warn(
        `‚ö†Ô∏è ${algorithmName} ne fait pas de classification de strat√©gie - test de classification bas√© sur strat√©gie d'origine`
      );

      // Cr√©er un r√©sultat de classification parfait puisque nous utilisons la strat√©gie d'origine
      const perfectMetrics: ValidationMetrics = {
        accuracy: 1.0,
        precision: { PERFECT: 1.0 },
        recall: { PERFECT: 1.0 },
        f1Score: { PERFECT: 1.0 },
        kappaCohen: 1.0,
        support: { PERFECT: predictions.length },
        confusionMatrix: [[predictions.length]],
        classLabels: ["PERFECT"],
      };

      // M√©triques par famille bas√©es sur les familles r√©elles
      const families = [
        ...new Set(goldStandard.map((gs) => gs.strategyFamily)),
      ];
      const byFamily: Record<string, ValidationMetrics> = {};

      families.forEach((family) => {
        byFamily[family] = {
          accuracy: 1.0,
          precision: { [family]: 1.0 },
          recall: { [family]: 1.0 },
          f1Score: { [family]: 1.0 },
          kappaCohen: 1.0,
          support: {
            [family]: goldStandard.filter((gs) => gs.strategyFamily === family)
              .length,
          },
          confusionMatrix: [
            [goldStandard.filter((gs) => gs.strategyFamily === family).length],
          ],
          classLabels: [family],
        };
      });

      return {
        testType: "classification",
        algorithmName,
        sampleSize: predictions.length,
        overallMetrics: perfectMetrics,
        byFamily,
        discrepancies: [], // Aucune divergence puisque nous utilisons la strat√©gie d'origine
        recommendations: [
          `${algorithmName} ne fait pas de classification de strat√©gie - utilise la strat√©gie d'origine (test non applicable)`,
        ],
      };
    }

    console.log(`üß™ Test classification: ${predictions.length} √©chantillons`);

    // Extraire les donn√©es pour la validation
    const actual = goldStandard.map((gs) => gs.expectedStrategyClassification);
    const predicted = predictions.map((p) => p.predictedStrategy || "UNKNOWN");

    // M√©triques globales
    const overallMetrics = this.calculateValidationMetrics(predicted, actual);

    // M√©triques par famille
    const families = [...new Set(goldStandard.map((gs) => gs.strategyFamily))];
    const byFamily: Record<string, ValidationMetrics> = {};

    for (const family of families) {
      const familyIndices = goldStandard
        .map((gs, i) => (gs.strategyFamily === family ? i : -1))
        .filter((i) => i !== -1);

      const familyActual = familyIndices.map((i) => actual[i]);
      const familyPredicted = familyIndices.map((i) => predicted[i]);

      byFamily[family] = this.calculateValidationMetrics(
        familyPredicted,
        familyActual
      );
    }

    // Analyse des divergences
    const discrepancies = this.analyzeDiscrepancies(
      predictions,
      goldStandard,
      "classification"
    );

    // Recommandations
    const recommendations = this.generateClassificationRecommendations(
      overallMetrics,
      byFamily,
      discrepancies
    );

    return {
      testType: "classification",
      algorithmName,
      sampleSize: predictions.length,
      overallMetrics,
      byFamily,
      discrepancies,
      recommendations,
    };
  }

  /**
   * Test 2: Validation pr√©diction des r√©actions
   * V√©rifie si l'algorithme pr√©dit correctement les r√©actions client (POSITIF/NEGATIF/NEUTRE)
   */
  async validatePredictionAccuracy(
    predictions: AlgorithmPrediction[],
    goldStandard: ValidationPair[],
    algorithmName: string
  ): Promise<PredictionValidationResult> {
    if (predictions.length !== goldStandard.length) {
      throw new Error("Taille diff√©rente entre pr√©dictions et gold standard");
    }

    console.log(`üß™ Test pr√©diction: ${predictions.length} √©chantillons`);

    // Extraire les donn√©es pour la validation
    const actual = goldStandard.map((gs) => gs.expectedClientReaction);
    const predicted = predictions.map((p) => p.predictedReaction);

    // M√©triques globales
    const overallMetrics = this.calculateValidationMetrics(predicted, actual);

    // M√©triques par strat√©gie conseiller
    const strategies = [
      ...new Set(goldStandard.map((gs) => gs.expectedStrategyClassification)),
    ];
    const byStrategy: Record<string, ValidationMetrics> = {};

    for (const strategy of strategies) {
      const strategyIndices = goldStandard
        .map((gs, i) =>
          gs.expectedStrategyClassification === strategy ? i : -1
        )
        .filter((i) => i !== -1);

      const strategyActual = strategyIndices.map((i) => actual[i]);
      const strategyPredicted = strategyIndices.map((i) => predicted[i]);

      byStrategy[strategy] = this.calculateValidationMetrics(
        strategyPredicted,
        strategyActual
      );
    }

    // Analyse des divergences
    const discrepancies = this.analyzeDiscrepancies(
      predictions,
      goldStandard,
      "prediction"
    );

    // Recommandations
    const recommendations = this.generatePredictionRecommendations(
      overallMetrics,
      byStrategy,
      discrepancies
    );

    return {
      testType: "prediction",
      algorithmName,
      sampleSize: predictions.length,
      overallMetrics,
      byStrategy,
      discrepancies,
      recommendations,
    };
  }

  /**
   * Validation compl√®te avec les deux tests
   */
  async validateDualPerformance(
    predictions: AlgorithmPrediction[],
    goldStandard: ValidationPair[],
    algorithmName: string
  ): Promise<DualValidationResult> {
    const classificationResult = await this.validateClassificationAccuracy(
      predictions,
      goldStandard,
      algorithmName
    );

    const predictionResult = await this.validatePredictionAccuracy(
      predictions,
      goldStandard,
      algorithmName
    );

    // Analyse crois√©e
    const crossAnalysis = this.performCrossAnalysis(
      classificationResult,
      predictionResult,
      goldStandard
    );

    // R√©sum√© ex√©cutif
    const summary = this.generateExecutiveSummary(
      classificationResult,
      predictionResult,
      crossAnalysis
    );

    return {
      classification: classificationResult,
      prediction: predictionResult,
      crossAnalysis,
      summary,
    };
  }

  /**
   * Calcule les m√©triques de validation standard
   */
  private calculateValidationMetrics(
    predicted: string[],
    actual: string[]
  ): ValidationMetrics {
    if (predicted.length !== actual.length) {
      throw new Error("Arrays de taille diff√©rente");
    }

    const uniqueLabels = [...new Set([...predicted, ...actual])];
    const confusionMatrix = this.buildConfusionMatrix(
      predicted,
      actual,
      uniqueLabels
    );

    // Accuracy globale
    const correct = predicted.filter((p, i) => p === actual[i]).length;
    const accuracy = correct / predicted.length;

    // Precision, Recall, F1 par classe
    const precision: Record<string, number> = {};
    const recall: Record<string, number> = {};
    const f1Score: Record<string, number> = {};
    const support: Record<string, number> = {};

    uniqueLabels.forEach((label, labelIndex) => {
      // Support (nombre d'instances r√©elles de cette classe)
      support[label] = actual.filter((a) => a === label).length;

      if (support[label] === 0) {
        precision[label] = 0;
        recall[label] = 0;
        f1Score[label] = 0;
        return;
      }

      // True Positives, False Positives, False Negatives
      const tp = confusionMatrix[labelIndex][labelIndex];
      const fp = confusionMatrix.reduce(
        (sum, row, i) => (i !== labelIndex ? sum + row[labelIndex] : sum),
        0
      );
      const fn = confusionMatrix[labelIndex].reduce(
        (sum, val, i) => (i !== labelIndex ? sum + val : sum),
        0
      );

      // Calculs
      precision[label] = fp + tp > 0 ? tp / (tp + fp) : 0;
      recall[label] = fn + tp > 0 ? tp / (tp + fn) : 0;

      const p = precision[label];
      const r = recall[label];
      f1Score[label] = p + r > 0 ? (2 * p * r) / (p + r) : 0;
    });

    // Kappa de Cohen
    const kappaCohen = this.calculateCohenKappa(
      predicted,
      actual,
      uniqueLabels
    );

    return {
      accuracy,
      precision,
      recall,
      f1Score,
      kappaCohen,
      support,
      confusionMatrix,
      classLabels: uniqueLabels,
    };
  }

  /**
   * Construit la matrice de confusion
   */
  private buildConfusionMatrix(
    predicted: string[],
    actual: string[],
    labels: string[]
  ): number[][] {
    const matrix: number[][] = labels.map(() => labels.map(() => 0));

    predicted.forEach((pred, i) => {
      const actualLabel = actual[i];
      const predIndex = labels.indexOf(pred);
      const actualIndex = labels.indexOf(actualLabel);

      if (predIndex !== -1 && actualIndex !== -1) {
        matrix[actualIndex][predIndex]++;
      }
    });

    return matrix;
  }

  /**
   * Calcule le coefficient Kappa de Cohen
   */
  private calculateCohenKappa(
    predicted: string[],
    actual: string[],
    labels: string[]
  ): number {
    const n = predicted.length;
    const confusionMatrix = this.buildConfusionMatrix(
      predicted,
      actual,
      labels
    );

    // Observed agreement
    const observedAgreement =
      confusionMatrix.reduce((sum, row, i) => sum + row[i], 0) / n;

    // Expected agreement
    let expectedAgreement = 0;
    labels.forEach((_, i) => {
      const actualCount = confusionMatrix.reduce((sum, row) => sum + row[i], 0);
      const predictedCount = confusionMatrix[i].reduce(
        (sum, val) => sum + val,
        0
      );
      expectedAgreement += (actualCount * predictedCount) / (n * n);
    });

    // Kappa
    return expectedAgreement === 1
      ? 0
      : (observedAgreement - expectedAgreement) / (1 - expectedAgreement);
  }

  /**
   * Analyse les divergences entre pr√©dictions et gold standard
   */
  private analyzeDiscrepancies(
    predictions: AlgorithmPrediction[],
    goldStandard: ValidationPair[],
    testType: "classification" | "prediction"
  ): DiscrepancyItem[] {
    const discrepancies: DiscrepancyItem[] = [];

    predictions.forEach((pred, i) => {
      const gs = goldStandard[i];
      const predicted =
        testType === "classification"
          ? pred.predictedStrategy
          : pred.predictedReaction;
      const actual =
        testType === "classification"
          ? gs.expectedStrategyClassification
          : gs.expectedClientReaction;

      if (predicted !== actual) {
        let discrepancyType: DiscrepancyItem["discrepancyType"] =
          "misclassification";

        // Analyse plus fine du type d'erreur
        if (testType === "prediction") {
          if (predicted === "POSITIF" && actual !== "POSITIF") {
            discrepancyType = "false_positive";
          } else if (predicted !== "POSITIF" && actual === "POSITIF") {
            discrepancyType = "false_negative";
          }
        }

        discrepancies.push({
          id: pred.id,
          inputVerbatim: pred.inputVerbatim,
          predicted: predicted || "UNKNOWN",
          actual: actual,
          confidence: pred.confidence,
          discrepancyType,
          context: {
            strategy: gs.expectedStrategyClassification,
            family: gs.strategyFamily,
            callId: gs.callId,
          },
        });
      }
    });

    return discrepancies.sort((a, b) => b.confidence - a.confidence); // Plus confiantes en premier
  }

  /**
   * G√©n√®re les recommandations pour classification
   */
  private generateClassificationRecommendations(
    overallMetrics: ValidationMetrics,
    byFamily: Record<string, ValidationMetrics>,
    discrepancies: DiscrepancyItem[]
  ): string[] {
    const recommendations: string[] = [];

    // Analyse performance globale
    if (overallMetrics.accuracy < 0.7) {
      recommendations.push(
        "Performance de classification faible (< 70%). R√©viser les features utilis√©es."
      );
    } else if (overallMetrics.accuracy > 0.85) {
      recommendations.push(
        "Excellente performance de classification (> 85%). Algorithme fiable."
      );
    }

    // Analyse par famille
    const worstFamily = Object.entries(byFamily).sort(
      ([, a], [, b]) => a.accuracy - b.accuracy
    )[0];

    if (worstFamily && worstFamily[1].accuracy < 0.6) {
      recommendations.push(
        `Famille ${worstFamily[0]} particuli√®rement difficile (${(
          worstFamily[1].accuracy * 100
        ).toFixed(1)}% accuracy). Enrichir les patterns.`
      );
    }

    // Analyse des erreurs hautement confiantes
    const highConfidenceErrors = discrepancies.filter(
      (d) => d.confidence > 0.8
    );
    if (highConfidenceErrors.length > discrepancies.length * 0.1) {
      recommendations.push(
        "Nombreuses erreurs avec haute confiance. Calibrer les scores de confiance."
      );
    }

    return recommendations;
  }

  /**
   * G√©n√®re les recommandations pour pr√©diction
   */
  private generatePredictionRecommendations(
    overallMetrics: ValidationMetrics,
    byStrategy: Record<string, ValidationMetrics>,
    discrepancies: DiscrepancyItem[]
  ): string[] {
    const recommendations: string[] = [];

    // Analyse performance globale
    if (overallMetrics.accuracy < 0.6) {
      recommendations.push(
        "Pr√©diction des r√©actions difficile (< 60%). Consid√©rer des features contextuelles."
      );
    }

    // Analyse des r√©actions difficiles √† pr√©dire
    const reactionF1 = overallMetrics.f1Score;
    const worstReaction = Object.entries(reactionF1).sort(
      ([, a], [, b]) => a - b
    )[0];

    if (worstReaction && worstReaction[1] < 0.5) {
      recommendations.push(
        `R√©action ${
          worstReaction[0]
        } difficile √† pr√©dire (F1: ${worstReaction[1].toFixed(
          3
        )}). Analyser patterns sp√©cifiques.`
      );
    }

    // Analyse par strat√©gie
    const bestStrategy = Object.entries(byStrategy).sort(
      ([, a], [, b]) => b.accuracy - a.accuracy
    )[0];

    if (bestStrategy && bestStrategy[1].accuracy > 0.75) {
      recommendations.push(
        `Strat√©gie ${bestStrategy[0]} pr√©dit bien les r√©actions (${(
          bestStrategy[1].accuracy * 100
        ).toFixed(1)}%). Analyser pourquoi.`
      );
    }

    return recommendations;
  }

  /**
   * Analyse crois√©e entre classification et pr√©diction
   */
  private performCrossAnalysis(
    classificationResult: ClassificationValidationResult,
    predictionResult: PredictionValidationResult,
    goldStandard: ValidationPair[]
  ): DualValidationResult["crossAnalysis"] {
    // Strat√©gies avec meilleure pr√©diction
    const strategiesWithBestPrediction = Object.entries(
      predictionResult.byStrategy
    )
      .map(([strategy, metrics]) => ({
        strategy,
        f1Score:
          Object.values(metrics.f1Score).reduce((a, b) => a + b, 0) /
          Object.values(metrics.f1Score).length,
      }))
      .sort((a, b) => b.f1Score - a.f1Score);

    // R√©actions les plus difficiles √† pr√©dire
    const reactionF1Scores = predictionResult.overallMetrics.f1Score;
    const reactionsHardestToPredict = Object.entries(reactionF1Scores)
      .map(([reaction, f1Score]) => ({ reaction, f1Score }))
      .sort((a, b) => a.f1Score - b.f1Score);

    // Corr√©lation entre performance classification et pr√©diction
    const correlationClassificationVsPrediction = this.calculateCorrelation(
      classificationResult.overallMetrics.accuracy,
      predictionResult.overallMetrics.accuracy
    );

    return {
      strategiesWithBestPrediction,
      reactionsHardestToPredict,
      correlationClassificationVsPrediction,
    };
  }

  /**
   * G√©n√®re le r√©sum√© ex√©cutif
   */
  private generateExecutiveSummary(
    classificationResult: ClassificationValidationResult,
    predictionResult: PredictionValidationResult,
    crossAnalysis: DualValidationResult["crossAnalysis"]
  ): DualValidationResult["summary"] {
    const classAccuracy = classificationResult.overallMetrics.accuracy;
    const predAccuracy = predictionResult.overallMetrics.accuracy;

    // Recommandation d'usage
    let recommendedUseCase: string;
    if (classAccuracy > 0.8 && predAccuracy > 0.7) {
      recommendedUseCase =
        "Algorithme fiable pour classification ET pr√©diction";
    } else if (classAccuracy > 0.75) {
      recommendedUseCase =
        "Recommand√© principalement pour classification des strat√©gies";
    } else if (predAccuracy > 0.65) {
      recommendedUseCase =
        "Recommand√© principalement pour pr√©diction des r√©actions";
    } else {
      recommendedUseCase = "Performance insuffisante - r√©vision n√©cessaire";
    }

    // Fiabilit√© de la confiance
    const highConfErrors = [
      ...classificationResult.discrepancies.filter((d) => d.confidence > 0.8),
      ...predictionResult.discrepancies.filter((d) => d.confidence > 0.8),
    ];
    const totalDiscrepancies =
      classificationResult.discrepancies.length +
      predictionResult.discrepancies.length;
    const confidenceReliability =
      totalDiscrepancies > 0
        ? 1 - highConfErrors.length / totalDiscrepancies
        : 1;

    return {
      overallClassificationAccuracy: classAccuracy,
      overallPredictionAccuracy: predAccuracy,
      recommendedUseCase,
      confidenceReliability,
    };
  }

  /**
   * Calcule une corr√©lation simple (placeholder)
   */
  private calculateCorrelation(value1: number, value2: number): number {
    // Corr√©lation simplifi√©e - dans un vrai cas, utiliser multiple √©chantillons
    return Math.abs(value1 - value2) < 0.1 ? 0.8 : 0.3;
  }
}
