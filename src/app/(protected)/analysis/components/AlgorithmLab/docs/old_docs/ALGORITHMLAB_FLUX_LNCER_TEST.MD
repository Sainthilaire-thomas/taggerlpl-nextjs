# 1) L‚ÄôUI que tu vois (haut de page)

- Tu es dans **Level1Interface** .
- Tu choisis l‚Äôonglet **X / Y / M1 / M2 / M3** ‚Üí √ßa monte le composant `*ValidationInterface` correspondant (ex. `XValidationInterface`, `M2ValidationInterface`, etc.).
- Dans ce composant, on rend le **RunPanel** (slider + bouton ‚ÄúLancer test‚Äù) + un bloc r√©sultats (`ResultsPanel`).

# 2) Tu cliques ‚ÄúLancer test‚Äù

- Le bouton d√©clenche un handler `onRun` fourni par la **ValidationInterface** .
- Ce handler appelle le **hook** de la variable (ex. `useXAlgorithmTesting`, `useM2AlgorithmTesting`) avec la **taille d‚Äô√©chantillon** (du slider).

# 3) Le hook ‚Äúrunner‚Äù fabrique les entr√©es & ex√©cute l‚Äôalgo

Dans le hook (identique en logique pour X/Y/M1/M2/M3) :

1. **R√©cup√©ration des donn√©es** (source unique)

   On lit la mati√®re premi√®re via **TaggingDataContext** (tes tours tagg√©s, ordonn√©s, avec `verbatim`, `tag`, `call_id`, `start_time`, `next_turn_verbatim`, etc.).

   Pour M2, on construit la fen√™tre **‚àí2 / ‚àí1 / 0 / +1** √† partir de ces tours.

2. **√âchantillonnage**

   On prend **N √©l√©ments** (la valeur du slider).

   üëâ C‚Äôest ici qu‚Äôil faut s‚Äôassurer qu‚Äôon renvoie vraiment **N** lignes (pas 3 si tu demandes 50 üòâ).

3. **Pr√©paration des inputs**

   - **X** : input = le **tour conseiller (T0)** (string)
   - **Y** : input = le **tour client (T+1)** (string)
   - **M1** : input = **T0** (string)
   - **M2** : input = un objet `{ t0, t1, ... }` (T0 = conseiller ; T1 = client +1), on peut aussi passer `prev1/prev2` en m√©tadonn√©es d‚Äôaide
   - **M3** : selon ta d√©finition, g√©n√©ralement num√©rique sur T0

4. **R√©cup√©ration de l‚Äôalgo**

   On r√©cup√®re l‚Äôinstance dans `algorithmRegistry` par son nom (s√©lectionn√© dans la ValidationInterface).

5. **Ex√©cution**

   On appelle `algo.run(input)` (ou `algo.batchRun(inputs)` si dispo).

   Chaque sortie renvoie **au minimum** :

   - `prediction` (string)
   - `confidence` (0..1)
   - `processingTime` (ms)
   - `metadata` optionnel (o√π on aime bien passer le **contexte** )

6. **Mapping vers la table (format unique)**

   Pour chaque √©l√©ment, on cr√©e un **`TVValidationResult`** (c‚Äôest le contrat commun que la table attend) :

   - `verbatim` = **T0** (affich√© en ligne ‚Äú0‚Äù dans la colonne Contexte)
   - `predicted` = sortie brute de l‚Äôalgo (string)
   - `goldStandard` = **tag annot√© du tour conseiller (T0)**
     - Pour **X** : c‚Äôest vraiment le gold **X** ‚Üí on peut calculer `correct = predicted === goldStandard`
     - Pour **M1/M2/M3** : on **affiche pour m√©moire** ce tag, mais **on ne score pas** (mettre `correct` **undefined** )
   - `confidence`, `processingTime` = valeurs renvoy√©es par l‚Äôalgo
   - `metadata` (cl√© indispensable pour le Contexte & Annot) :
     - `prev2_turn_verbatim`, `prev1_turn_verbatim`, `next_turn_verbatim`
     - (facultatif) `next_turn_tag`
     - `turnId` (ou `id`) pour que le bouton **Annot.** fonctionne
     - `callId`, `speaker`, `startTime`, `endTime`
     - (sp√©cifiques) ex. `metadata.m2 = { value, scale }` pour M2

> ‚ö†Ô∏è Si **l‚Äôune** de ces cl√©s manque (par ex. `metadata.next_turn_verbatim`), la table **n‚Äôaffiche pas** la ligne correspondante du contexte.
>
> Idem si `goldStandard` est vide ‚Üí la puce verte est vide.
>
> Idem si le hook ne renvoie que 3 lignes ‚Üí tu verras 3/50.

# 4) Le rendu des r√©sultats

- La **ValidationInterface** passe `results` √† **ResultsPanel** avec `targetKind` (X/Y/M1/M2/M3).
- `ResultsPanel` :
  - calcule des m√©triques **classification** si `targetKind ‚àà {X,Y,M2}` (sinon num√©riques pour M1/M3)
  - g√®re les **filtres** (dont ‚ÄúD√©saccords uniquement‚Äù = lignes avec `correct === false`)
  - g√®re la **pagination** ou ‚Äúafficher tout‚Äù
  - rend le **header** (stats, bouton fine-tuning, switch d√©saccords)
  - rend le **tableau** (`ResultsTableBody`)
- **ResultsTableBody** (commun) lit **exclusivement** ces champs :
  - `verbatim` (ligne 0)
  - `metadata.prev2_turn_verbatim`, `metadata.prev1_turn_verbatim`, `metadata.next_turn_verbatim` (lignes ‚àí2/‚àí1/+1)
  - `predicted` (Sortie mod√®le)
  - `goldStandard` (R√©f√©rence (gold))
  - `confidence`, `processingTime`
  - `AnnotationList` : a besoin d‚Äôun `turnId` + infos algorithme
  - puis **extraColumns** (d√©pendent de la variable ; ex. pour M2 on pioche dans `metadata.m2`)

# Flux Y (clic ‚ÄúLANCER TEST‚Äù)

1. **Level1Interface ‚Üí YValidationInterface ‚Üí BaseAlgorithmTesting**

   `BaseAlgorithmTesting` is the generic screen (algo picker, RunPanel, ResultsPanel).

2. **BaseAlgorithmTesting ‚Üí useLevel1Testing(target="Y")**

   This hook is the ‚Äúguichet unique‚Äù pour X & Y (& M1 via branche d√©di√©e). It:

   - **Charge le dataset** via `TaggingDataContext` (`allTurnTagged`).
   - **Construit un gold standard unifi√©** avec `mapTurnsToGoldStandard(...)` :

     - **√©chantillon ‚Äúconseiller‚Äù** (courant `t`): `expectedTag = normalizeLabel(t.tag)`, contexte prev2/prev1/next1.
     - **√©chantillon ‚Äúclient‚Äù** (tour suivant de `t`) si `next_turn_*` pr√©sents:

       `expectedTag = normalizeLabel(t.next_turn_tag)`, verbatim = `t.next_turn_verbatim`, contexte recalcul√© autour du tour client.

   - **D√©termine la cible** √† partir de `algorithm.describe().target`.

     Pour Y ‚áí `target = "client"`.

   - **Filtre la base** : `base = goldStandardData.filter(s => s.metadata.target === "client")`.
   - **√âchantillonne** `sampleSize` √©l√©ments, **appelle l‚Äôalgo** (`/api/algolab/classifiers` si LLM, sinon `algo.run(verbatim)`), et **normalise** en `TVValidationResult`.

3. **ResultsPanel ‚Üí ResultsTableHeader/Body**

   Les **colonnes communes** (Contexte, Sortie mod√®le brut, R√©f√©rence (gold), Confiance, Temps, Annot.) sont **toujours** les m√™mes.

   Les colonnes sp√©cifiques viennent de `buildExtraColumnsForTarget("Y")`.
