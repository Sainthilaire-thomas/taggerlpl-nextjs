// src/app/(protected)/analysis/components/AlgorithmLab/algorithms/level1/XAlgorithms/OpenAIXClassifier.ts

import type {
  UniversalAlgorithm,
  AlgorithmDescriptor,
  UniversalResult,
} from "@/types/algorithm-lab/algorithms/base";

type OpenAIConfig = {
  apiKey?: string; // MAJ √† chaud possible via updateConfig()
  model?: string;
  temperature?: number;
  maxTokens?: number;
  timeout?: number;
  enableFallback?: boolean; // en cas d'erreur ‚Üí AUTRE_NON_RECONNU
};

const LABELS = [
  "ENGAGEMENT",
  "OUVERTURE",
  "REFLET_JE",
  "REFLET_VOUS",
  "REFLET_ACQ",
  "EXPLICATION",
  "AUTRE_NON_RECONNU",
] as const;

export class OpenAIXClassifier implements UniversalAlgorithm {
  private apiKey: string;
  private config: Required<Omit<OpenAIConfig, "apiKey">>;

  constructor(config: OpenAIConfig = {}) {
    // ‚ö†Ô∏è ne jamais mettre NEXT_PUBLIC_* ici : la cl√© doit rester c√¥t√© serveur
    this.apiKey = config.apiKey || process.env.OPENAI_API_KEY || "";

    this.config = {
      model: "gpt-4o", // Plus performant que gpt-4o-mini pour la classification complexe
      temperature: 0, // Maintenir √† 0 pour la coh√©rence
      maxTokens: 16, // R√©duire pour forcer des r√©ponses concises
      timeout: config.timeout ?? 10000,
      enableFallback: config.enableFallback ?? true,
    };
  }

  describe(): AlgorithmDescriptor {
    return {
      name: "OpenAIXClassifier",
      displayName: "OpenAI ‚Äì X (conseiller)",
      version: "2.3.0", // Version corrig√©e
      type: "llm",
      target: "X",
      batchSupported: true,
      requiresContext: false,
      description:
        "Classification LLM des tours de parole CONSEILLER (ENGAGEMENT, OUVERTURE, REFLET_*, EXPLICATION). Sortie forc√©e JSON, fallback = AUTRE_NON_RECONNU.",
      examples: [
        { input: "je vais v√©rifier votre dossier", note: "ENGAGEMENT" },
        { input: "vous allez recevoir un email", note: "OUVERTURE" },
        { input: "je comprends votre situation", note: "REFLET_JE" },
        {
          input: "notre politique exige un contr√¥le pr√©alable",
          note: "EXPLICATION",
        },
      ],
    };
  }

  validateConfig(): boolean {
    // Validation basique c√¥t√© client
    return this.config.maxTokens > 0 && this.config.timeout > 0;
  }

  async run(input: unknown): Promise<UniversalResult> {
    const verbatim = String(input ?? "");
    const startTime = Date.now();

    // ‚îÄ‚îÄ LOGIQUE CORRIG√âE : D√©tection de l'environnement
    const isServer = typeof window === "undefined";

    if (isServer) {
      // ‚îÄ‚îÄ Chemin serveur : appel direct OpenAI
      return this.runServerSide(verbatim, startTime);
    } else {
      // ‚îÄ‚îÄ Chemin navigateur : passage par l'API interne Next.js
      return this.runClientSide(verbatim, startTime);
    }
  }

  private async runClientSide(
    verbatim: string,
    startTime: number
  ): Promise<UniversalResult> {
    try {
      console.log("üåê OpenAI Classification - Appel via API interne client");

      const response = await fetch("/api/algolab/classifiers", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({
          key: "OpenAIXClassifier",
          verbatim,
          timestamp: Date.now(), // Pour debug
        }),
      });

      if (!response.ok) {
        const errorText = await response
          .text()
          .catch(() => response.statusText);
        console.error(`‚ùå API Error ${response.status}:`, errorText);
        return this.naFallback(
          startTime,
          `api_status_${response.status}:${errorText}`
        );
      }

      const data = await response.json();
      console.log("‚úÖ API Response received:", data);

      if (!data?.ok || !Array.isArray(data.results) || !data.results[0]) {
        console.error("‚ùå Invalid API payload:", data);
        return this.naFallback(startTime, "api_invalid_payload");
      }

      return data.results[0] as UniversalResult;
    } catch (error: any) {
      console.error("‚ùå Client API call failed:", error);
      return this.naFallback(startTime, error?.message ?? "api_network_error");
    }
  }

  // Ajoutez cette m√©thode dans votre classe OpenAIXClassifier

  private parseOpenAIResponse(data: any, startTime: number): UniversalResult {
    const rawContent = data?.choices?.[0]?.message?.content ?? "";
    let label = "AUTRE_NON_RECONNU";

    // Parse JSON avec fallback am√©lior√©
    try {
      const parsed = JSON.parse(rawContent);
      if (parsed?.label && LABELS.includes(parsed.label)) {
        label = parsed.label;
      }
    } catch {
      // Fallback avec priorit√©s de la th√®se
      const content = rawContent.toUpperCase();

      // Priorit√© 1: ENGAGEMENT
      if (content.includes("ENGAGEMENT")) label = "ENGAGEMENT";
      // Priorit√© 2: OUVERTURE
      else if (content.includes("OUVERTURE")) label = "OUVERTURE";
      // Priorit√© 3: REFLET (avec sous-types)
      else if (content.includes("REFLET_VOUS")) label = "REFLET_VOUS";
      else if (content.includes("REFLET_JE")) label = "REFLET_JE";
      else if (content.includes("REFLET_ACQ")) label = "REFLET_ACQ";
      else if (content.includes("REFLET")) label = "REFLET_ACQ"; // par d√©faut
      // Priorit√© 4: EXPLICATION
      else if (content.includes("EXPLICATION")) label = "EXPLICATION";
    }

    return {
      prediction: label,
      confidence: label === "AUTRE_NON_RECONNU" ? 0.25 : 0.85,
      processingTime: Date.now() - startTime,
      algorithmVersion: this.config.model,
      metadata: {
        target: "X",
        inputType: "string",
        executionPath: ["openai_gpt_json"],
        provider: "openai",
        details: {
          family: this.familyFromX(label),
          rawResponse: rawContent,
          parseMethod: label !== "AUTRE_NON_RECONNU" ? "success" : "fallback",
        },
        raw: data,
      },
    };
  }

  private applyHierarchicalRules(label: string, verbatim: string): string {
    // V√©rification de coh√©rence avec les r√®gles de la th√®se
    const cleanVerbatim = verbatim.toLowerCase();

    // Force ENGAGEMENT si verbe d'action + "je"
    if (
      (cleanVerbatim.includes("je vais") ||
        cleanVerbatim.includes("je fais") ||
        cleanVerbatim.includes("je v√©rifie")) &&
      label !== "ENGAGEMENT"
    ) {
      return "ENGAGEMENT";
    }

    // Force OUVERTURE si instruction client
    if (
      (cleanVerbatim.includes("vous allez") ||
        cleanVerbatim.includes("veuillez") ||
        cleanVerbatim.includes("il faut que vous")) &&
      !["ENGAGEMENT", "OUVERTURE"].includes(label)
    ) {
      return "OUVERTURE";
    }

    return label;
  }
  private async runServerSide(
    verbatim: string,
    startTime: number
  ): Promise<UniversalResult> {
    console.log("üîß OpenAI Classification - Appel direct serveur");

    if (!this.apiKey) {
      console.error("‚ùå No OpenAI API key available");
      return this.naFallback(startTime, "no-api-key");
    }

    const controller = new AbortController();
    const timer = setTimeout(() => {
      console.warn("‚è∞ OpenAI API timeout");
      controller.abort();
    }, this.config.timeout);

    try {
      console.log(`ü§ñ Calling OpenAI API with model: ${this.config.model}`);

      const response = await fetch(
        "https://api.openai.com/v1/chat/completions",
        {
          method: "POST",
          signal: controller.signal,
          headers: {
            "Content-Type": "application/json",
            Authorization: `Bearer ${this.apiKey}`,
          },
          body: JSON.stringify({
            model: this.config.model,
            temperature: this.config.temperature,
            max_tokens: this.config.maxTokens,

            // üîí Sortie structur√©e : un JSON strict { "label": <enum> }
            response_format: {
              type: "json_schema",
              json_schema: {
                name: "x_label",
                strict: true,
                schema: {
                  type: "object",
                  additionalProperties: false,
                  properties: {
                    label: { type: "string", enum: [...LABELS] },
                  },
                  required: ["label"],
                },
              },
            },

            messages: this.buildMessages(verbatim),
          }),
        }
      );

      clearTimeout(timer);

      if (!response.ok) {
        let reason = `openai_status_${response.status}`;
        try {
          const errorData = await response.json();
          if (errorData?.error?.message) {
            reason += `:${errorData.error.message}`;
          }
          console.error("‚ùå OpenAI API Error:", errorData);
        } catch {}
        return this.naFallback(startTime, reason);
      }

      const data = await response.json();
      console.log("‚úÖ OpenAI API Response:", data);

      return this.parseOpenAIResponse(data, startTime);
    } catch (error: any) {
      clearTimeout(timer);
      console.error("‚ùå OpenAI API call failed:", error);
      return this.naFallback(startTime, error?.message ?? "network_error");
    }
  }

  // Prompt OpenAI optimis√© bas√© sur l'analyse du corpus r√©el
  // Ajouter cette m√©thode dans votre classe OpenAIXClassifier

  // Version debug simplifi√©e - compatible avec votre JSON schema

  // Prompt am√©lior√© v2 - bas√© sur les erreurs observ√©es

  // Prompt bas√© sur la logique linguistique et pragmatique

  private buildMessages(verbatim: string) {
    return [
      {
        role: "system",
        content: `Tu es un expert en classification des strat√©gies linguistiques des conseillers en centre de contact.

R√àGLE FONDAMENTALE - HI√âRARCHIE DE PRIORIT√â :
1. ENGAGEMENT > 2. OUVERTURE > 3. REFLET > 4. EXPLICATION

Si plusieurs fonctions coexistent, choisis TOUJOURS la plus haute dans cette hi√©rarchie.

CAT√âGORIES ET MARQUEURS PRIORITAIRES :

üéØ ENGAGEMENT (PRIORIT√â 1) - Action du conseiller
MARQUEURS FORTS : "je vais/fais/v√©rifie/transf√®re/m'occupe", "je suis en train de", futur 1√®re personne
LOGIQUE : Le conseiller annonce une action concr√®te qu'il r√©alise
- "D'accord, je vais v√©rifier votre dossier" ‚Üí ENGAGEMENT (action prime sur acquiescement)
- "Je comprends, je transf√®re maintenant" ‚Üí ENGAGEMENT (action prime sur empathie)

üéØ OUVERTURE (PRIORIT√â 2) - Action du client  
MARQUEURS FORTS : "vous allez/recevrez/pourrez/devrez", imp√©ratifs ("pr√©cisez", "envoyez"), "veuillez", "il faut que vous"
LOGIQUE : Le conseiller oriente le client vers une action
- "Vous pouvez aller sur le site parce que..." ‚Üí OUVERTURE (instruction prime sur explication)
- "Il faut pr√©ciser l'heure et la station" ‚Üí OUVERTURE

üéØ REFLET (PRIORIT√â 3) - Reformulation/Acquiescement
SOUS-TYPES par efficacit√© d√©croissante :
- REFLET_VOUS : description client SANS instruction/justification ("Je vois que vous avez appel√©")
- REFLET_JE : √©tat mental conseiller ("je comprends/vois/entends")  
- REFLET_ACQ : micro-tours ‚â§20 chars ("oui", "d'accord", "ok")
EXCLUSIONS : si donn√©es chiffr√©es ou marqueurs instruction/explication ‚Üí pas REFLET

üéØ EXPLICATION (PRIORIT√â 4) - Justification/Proc√©dure
MARQUEURS : "parce que", "car", "le syst√®me fonctionne", "notre politique", "c'est pour √ßa que"
LOGIQUE : Justification institutionnelle sans action concr√®te
- "Notre syst√®me fonctionne en trois √©tapes" ‚Üí EXPLICATION
- "C'est normal/faux" (correction normative) ‚Üí EXPLICATION

R√àGLES DE D√âPARTAGE CRITIQUES :
- Action pr√©sente ‚Üí ENGAGEMENT/OUVERTURE m√™me si acquiescement en d√©but
- Instruction client ‚Üí OUVERTURE m√™me si justification apr√®s
- Donn√©es chiffr√©es/quantifications ‚Üí EXPLICATION (pas REFLET)
- Micro-tour seul ‚Üí REFLET_ACQ, mais si suivi d'instruction ‚Üí prendre l'ensemble`,
      },

      // Exemples avec cas limites de la th√®se
      { role: "user", content: "D'accord, je vais faire le n√©cessaire" },
      { role: "assistant", content: '{"label": "ENGAGEMENT"}' },

      {
        role: "user",
        content: "Vous pouvez aller sur le site parce que c'est plus rapide",
      },
      { role: "assistant", content: '{"label": "OUVERTURE"}' },

      { role: "user", content: "Je comprends, mais je vais v√©rifier" },
      { role: "assistant", content: '{"label": "ENGAGEMENT"}' },

      // Cas pi√®ge REFLET
      { role: "user", content: "Je vois que vous avez d√©j√† appel√© hier" },
      { role: "assistant", content: '{"label": "REFLET_VOUS"}' },

      { role: "user", content: "Je vois que vous avez re√ßu 1504,29 ‚Ç¨" },
      { role: "assistant", content: '{"label": "EXPLICATION"}' },

      { role: "user", content: "Il faut bien pr√©ciser l'heure et la station" },
      { role: "assistant", content: '{"label": "OUVERTURE"}' },

      // Instance √† classer
      { role: "user", content: verbatim.trim() },
    ];
  }

  async batchRun(inputs: unknown[]): Promise<UniversalResult[]> {
    console.log(`üîÑ Batch processing ${inputs.length} items`);
    const results: UniversalResult[] = [];

    for (let i = 0; i < inputs.length; i++) {
      console.log(`Processing item ${i + 1}/${inputs.length}`);
      // eslint-disable-next-line no-await-in-loop
      results.push(await this.run(inputs[i]));
      // eslint-disable-next-line no-await-in-loop
      await new Promise((r) => setTimeout(r, 120)); // Rate limiting
    }

    return results;
  }

  // ‚îÄ‚îÄ API live config
  getConfig() {
    return {
      apiKey: this.apiKey ? "***CONFIGURED***" : "***NOT_SET***",
      ...this.config,
    };
  }

  updateConfig(partial: Partial<OpenAIConfig>) {
    if (typeof partial.apiKey === "string") this.apiKey = partial.apiKey;
    if (typeof partial.model === "string") this.config.model = partial.model;
    if (typeof partial.temperature === "number")
      this.config.temperature = partial.temperature;
    if (typeof partial.maxTokens === "number")
      this.config.maxTokens = partial.maxTokens;
    if (typeof partial.timeout === "number")
      this.config.timeout = partial.timeout;
    if (typeof partial.enableFallback === "boolean")
      this.config.enableFallback = partial.enableFallback;
  }

  // ‚îÄ‚îÄ Helpers
  private naFallback(startTime: number, reason: string): UniversalResult {
    const label = "AUTRE_NON_RECONNU";
    console.warn(`‚ö†Ô∏è Fallback triggered: ${reason}`);

    return {
      prediction: label,
      confidence: this.config.enableFallback ? 0.25 : 0,
      processingTime: Date.now() - startTime,
      algorithmVersion: "openai-no-call",
      metadata: {
        target: "X",
        inputType: "string",
        executionPath: ["no_api_or_error"],
        details: { family: this.familyFromX(label), reason },
      },
    };
  }

  private familyFromX(label: string): string {
    if (label.includes("REFLET")) return "REFLET";
    if (label.includes("ENGAGEMENT")) return "ENGAGEMENT";
    if (label.includes("OUVERTURE")) return "OUVERTURE";
    if (label.includes("EXPLICATION")) return "EXPLICATION";
    return "AUTRE";
  }
}
