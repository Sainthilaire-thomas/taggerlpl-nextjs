#!/usr/bin/env node
// apply-accurate-transformations.mjs
// Applique les transformations pr√©cises bas√©es sur votre architecture unifi√©e

import fs from "fs/promises";
import path from "path";

console.log("üéØ APPLICATION DES TRANSFORMATIONS PR√âCISES");
console.log("==========================================");

const PROJECT_ROOT = process.cwd();
const RULES_FILE = path.join(
  PROJECT_ROOT,
  "migration",
  "audit",
  "accurate-transformation-rules.json"
);
const BACKUP_DIR = path.join(PROJECT_ROOT, "migration", "backups");
const TRANSFORM_LOG = path.join(
  PROJECT_ROOT,
  "migration",
  "accurate-transformation.log"
);

console.log("üìã Chargement des r√®gles pr√©cises...");

try {
  const rulesContent = await fs.readFile(RULES_FILE, "utf8");
  const rules = JSON.parse(rulesContent);

  console.log(`‚úÖ R√®gles charg√©es: ${rules.metadata.strategy}`);
  console.log(
    `üìä Imports √† transformer: ${rules.metadata.total_imports_to_transform}`
  );
  console.log(`üéØ Architecture cible: ${rules.metadata.target_structure}`);

  // Cr√©er les r√©pertoires n√©cessaires
  await fs.mkdir(BACKUP_DIR, { recursive: true });

  // Initialiser le log
  const logHeader = `=== Transformation pr√©cise d√©marr√©e le ${new Date().toISOString()} ===\n`;
  await fs.writeFile(TRANSFORM_LOG, logHeader, "utf8");

  // Ex√©cuter la transformation par lots prioritaires
  await executeByPriorityBatches(rules);
} catch (error) {
  console.error("‚ùå Erreur:", error.message);
  if (error.code === "ENOENT") {
    console.log(
      "üí° Ex√©cutez d'abord: node migration/scripts/generate-accurate-transformation-rules.mjs"
    );
  }
  process.exit(1);
}

async function executeByPriorityBatches(rules) {
  console.log("\nüîÑ Ex√©cution par lots prioritaires...");

  // Validation pr√©-transformation
  console.log("\n1Ô∏è‚É£ Validation pr√©-transformation...");
  const preValidation = await runValidation(
    rules.validation_rules.pre_transformation
  );

  if (!preValidation.success) {
    console.error("‚ùå Validation pr√©-transformation √©chou√©e");
    preValidation.errors.forEach((err) => console.error(`   ${err}`));
    return;
  }

  console.log("‚úÖ Validation pr√©-transformation r√©ussie");

  // Identifier tous les fichiers candidats
  console.log("\n2Ô∏è‚É£ Identification des fichiers candidats...");
  const allCandidateFiles = await identifyAllCandidateFiles(rules);

  if (allCandidateFiles.length === 0) {
    console.log("üéâ Aucun fichier √† transformer trouv√©");
    return;
  }

  console.log(`üìÑ ${allCandidateFiles.length} fichiers candidats trouv√©s`);

  // Traitement par lots prioritaires
  console.log("\n3Ô∏è‚É£ Traitement par lots prioritaires...");
  const globalResults = {
    totalFiles: 0,
    successCount: 0,
    errorCount: 0,
    transformationsApplied: 0,
    errors: [],
  };

  for (const batch of rules.priority_batches) {
    console.log(`\nüì¶ LOT ${batch.batch}: ${batch.name}`);
    console.log(`   üìã ${batch.description}`);
    console.log(`   üéØ Priorit√©: ${batch.priority}`);

    // Filtrer les fichiers pour ce lot
    const batchFiles = filterFilesForBatch(allCandidateFiles, batch, rules);

    if (batchFiles.length === 0) {
      console.log(`   ‚ÑπÔ∏è Aucun fichier pour ce lot`);
      continue;
    }

    console.log(`   üìÑ ${batchFiles.length} fichiers √† traiter`);

    // Cr√©er les backups pour ce lot
    await createBackupsForBatch(batchFiles, batch.batch);

    // Appliquer les transformations pour ce lot
    const batchResults = await applyTransformationsForBatch(
      batchFiles,
      rules,
      batch
    );

    // Accumulation des r√©sultats
    globalResults.totalFiles += batchResults.totalFiles;
    globalResults.successCount += batchResults.successCount;
    globalResults.errorCount += batchResults.errorCount;
    globalResults.transformationsApplied += batchResults.transformationsApplied;
    globalResults.errors.push(...batchResults.errors);

    // Validation incr√©mentale si demand√©e
    if (rules.validation_rules.during_transformation) {
      console.log(`   üîç Validation incr√©mentale...`);
      const incrementalValidation = await runSimpleCompilationCheck();
      if (!incrementalValidation.success) {
        console.error(
          `   ‚ùå Validation incr√©mentale √©chou√©e pour le lot ${batch.batch}`
        );
        console.error(`   üîÑ Consid√©rez un rollback partiel si n√©cessaire`);
      } else {
        console.log(`   ‚úÖ Validation incr√©mentale r√©ussie`);
      }
    }

    console.log(
      `   üìä Lot ${batch.batch}: ${batchResults.successCount}/${batchResults.totalFiles} fichiers trait√©s, ${batchResults.transformationsApplied} transformations`
    );
  }

  // Validation post-transformation globale
  console.log("\n4Ô∏è‚É£ Validation post-transformation globale...");
  const postValidation = await runValidation(
    rules.validation_rules.post_transformation
  );

  // Rapport final
  generateFinalAccurateReport(globalResults, postValidation, rules);
}

async function identifyAllCandidateFiles(rules) {
  const candidateFiles = [];
  const srcPath = path.join(PROJECT_ROOT, "src");

  async function scanDirectory(dir) {
    try {
      const entries = await fs.readdir(dir, { withFileTypes: true });

      for (const entry of entries) {
        const fullPath = path.join(dir, entry.name);

        if (entry.isDirectory()) {
          await scanDirectory(fullPath);
        } else if (entry.name.endsWith(".ts") || entry.name.endsWith(".tsx")) {
          const content = await fs.readFile(fullPath, "utf8");

          // V√©rifier si le fichier contient des imports √† transformer
          const hasTargetImports = Object.keys(rules.source_path_mappings).some(
            (oldPath) => {
              return (
                content.includes(`from "${oldPath}"`) ||
                content.includes(`from '${oldPath}'`)
              );
            }
          );

          if (hasTargetImports) {
            candidateFiles.push({
              path: fullPath,
              relativePath: path.relative(PROJECT_ROOT, fullPath),
              content: content,
              patterns: detectPatterns(content, rules),
            });
          }
        }
      }
    } catch {
      // Ignorer les r√©pertoires inaccessibles
    }
  }

  await scanDirectory(srcPath);
  return candidateFiles;
}

function detectPatterns(content, rules) {
  const patterns = [];

  // D√©tecter les patterns pour chaque lot
  rules.priority_batches.forEach((batch) => {
    batch.patterns.forEach((pattern) => {
      if (content.includes(pattern)) {
        patterns.push({
          batch: batch.batch,
          pattern: pattern,
          priority: batch.priority,
        });
      }
    });
  });

  return patterns;
}

function filterFilesForBatch(allFiles, batch, rules) {
  return allFiles.filter((file) => {
    return file.patterns.some((pattern) => pattern.batch === batch.batch);
  });
}

async function createBackupsForBatch(batchFiles, batchNumber) {
  const batchBackupDir = path.join(BACKUP_DIR, `batch-${batchNumber}`);
  await fs.mkdir(batchBackupDir, { recursive: true });

  for (const file of batchFiles) {
    const backupFileName =
      file.relativePath.replace(/[\/\\]/g, "_") + ".backup";
    const backupPath = path.join(batchBackupDir, backupFileName);

    try {
      await fs.copyFile(file.path, backupPath);
      console.log(`     üíæ ${file.relativePath}`);
    } catch (error) {
      console.error(
        `     ‚ùå Erreur backup ${file.relativePath}: ${error.message}`
      );
    }
  }
}

async function applyTransformationsForBatch(batchFiles, rules, batch) {
  const results = {
    totalFiles: batchFiles.length,
    successCount: 0,
    errorCount: 0,
    transformationsApplied: 0,
    errors: [],
  };

  for (const file of batchFiles) {
    console.log(`     üîÑ ${file.relativePath}`);

    try {
      let transformedContent = file.content;
      let fileTransformations = 0;

      // Appliquer les mappings de chemins pour cette batch
      for (const [oldPath, newPath] of Object.entries(
        rules.source_path_mappings
      )) {
        // V√©rifier si ce mapping est pertinent pour cette batch
        const isRelevantForBatch = batch.patterns.some((pattern) =>
          oldPath.includes(pattern)
        );

        if (isRelevantForBatch) {
          const doubleQuotePattern = new RegExp(
            `from "${oldPath.replace(/[.*+?^${}()|[\]\\]/g, "\\$&")}"`,
            "g"
          );
          const singleQuotePattern = new RegExp(
            `from '${oldPath.replace(/[.*+?^${}()|[\]\\]/g, "\\$&")}'`,
            "g"
          );

          const beforeCount =
            (transformedContent.match(doubleQuotePattern) || []).length +
            (transformedContent.match(singleQuotePattern) || []).length;

          if (beforeCount > 0) {
            transformedContent = transformedContent.replace(
              doubleQuotePattern,
              `from "${newPath}"`
            );
            transformedContent = transformedContent.replace(
              singleQuotePattern,
              `from '${newPath}'`
            );

            fileTransformations += beforeCount;
            console.log(
              `       üìù ${oldPath} ‚Üí ${newPath} (${beforeCount} occurrences)`
            );
          }
        }
      }

      // √âcrire le fichier transform√©
      await fs.writeFile(file.path, transformedContent, "utf8");

      results.successCount++;
      results.transformationsApplied += fileTransformations;

      // Log d√©taill√©
      await fs.appendFile(
        TRANSFORM_LOG,
        `‚úÖ BATCH-${batch.batch} ${file.relativePath}: ${fileTransformations} transformations\n`,
        "utf8"
      );

      console.log(
        `       ‚úÖ ${fileTransformations} transformations appliqu√©es`
      );
    } catch (error) {
      results.errorCount++;
      results.errors.push(
        `BATCH-${batch.batch} ${file.relativePath}: ${error.message}`
      );

      console.error(`       ‚ùå Erreur: ${error.message}`);
      await fs.appendFile(
        TRANSFORM_LOG,
        `‚ùå BATCH-${batch.batch} ${file.relativePath}: ${error.message}\n`,
        "utf8"
      );
    }
  }

  return results;
}

async function runValidation(validationRules) {
  const results = {
    success: true,
    errors: [],
    warnings: [],
  };

  for (const rule of validationRules) {
    console.log(`  üîç ${rule.description}...`);

    if (rule.command) {
      try {
        const validationResult = await runCommand(
          rule.command,
          rule.timeout || 30000
        );

        if (!validationResult.success) {
          if (rule.required) {
            results.success = false;
            results.errors.push(
              `${rule.description}: ${validationResult.error || "Failed"}`
            );
          } else {
            results.warnings.push(
              `${rule.description}: ${validationResult.error || "Failed"}`
            );
          }
          console.log(`    ‚ùå √âchec`);
        } else {
          console.log(`    ‚úÖ Succ√®s`);
        }
      } catch (error) {
        if (rule.required) {
          results.success = false;
          results.errors.push(`${rule.description}: ${error.message}`);
        } else {
          results.warnings.push(`${rule.description}: ${error.message}`);
        }
        console.log(`    ‚ö†Ô∏è Erreur: ${error.message}`);
      }
    } else {
      // R√®gles sans commande (backup_creation, etc.)
      console.log(`    ‚úÖ V√©rifi√©`);
    }
  }

  return results;
}

async function runSimpleCompilationCheck() {
  try {
    const result = await runCommand("npx tsc --noEmit", 30000);
    return result;
  } catch (error) {
    return { success: false, error: error.message };
  }
}

async function runCommand(command, timeout) {
  const { spawn } = await import("child_process");

  return new Promise((resolve) => {
    const [cmd, ...args] = command.split(" ");
    const process = spawn(cmd, args, {
      cwd: PROJECT_ROOT,
      stdio: ["ignore", "pipe", "pipe"],
    });

    let output = "";
    let errors = "";

    process.stdout.on("data", (data) => (output += data.toString()));
    process.stderr.on("data", (data) => (errors += data.toString()));

    const timeoutId = setTimeout(() => {
      process.kill();
      resolve({ success: false, error: "Timeout" });
    }, timeout);

    process.on("close", (code) => {
      clearTimeout(timeoutId);
      resolve({
        success: code === 0,
        error: code !== 0 ? errors : null,
        output: output,
      });
    });
  });
}

function generateFinalAccurateReport(
  transformationResults,
  validationResults,
  rules
) {
  console.log("\nüìä RAPPORT FINAL DE TRANSFORMATION PR√âCISE");
  console.log("==========================================");

  console.log(`üìÅ Fichiers trait√©s: ${transformationResults.totalFiles}`);
  console.log(`‚úÖ Succ√®s: ${transformationResults.successCount}`);
  console.log(`‚ùå Erreurs: ${transformationResults.errorCount}`);
  console.log(
    `üîÑ Transformations appliqu√©es: ${transformationResults.transformationsApplied}`
  );

  // Afficher le d√©tail par lot
  console.log("\nüì¶ R√©sum√© par lot:");
  rules.priority_batches.forEach((batch) => {
    console.log(`   Lot ${batch.batch} (${batch.priority}): ${batch.name}`);
  });

  if (validationResults.success) {
    console.log("‚úÖ Validation finale: SUCC√àS");
  } else {
    console.log("‚ùå Validation finale: √âCHEC");
    validationResults.errors.forEach((err) => console.log(`   ${err}`));
  }

  if (validationResults.warnings.length > 0) {
    console.log("‚ö†Ô∏è Avertissements:");
    validationResults.warnings.forEach((warn) => console.log(`   ${warn}`));
  }

  console.log("\nüìã Fichiers g√©n√©r√©s:");
  console.log(`   üíæ Backups par lot: ${BACKUP_DIR}/batch-*`);
  console.log(`   üìù Log d√©taill√©: ${TRANSFORM_LOG}`);

  if (validationResults.success && transformationResults.errorCount === 0) {
    console.log("\nüéâ TRANSFORMATION PR√âCISE TERMIN√âE AVEC SUCC√àS!");
    console.log("\nüéØ Prochaines √©tapes:");
    console.log("   1. Tester l'application: npm run dev");
    console.log("   2. V√©rifier les fonctionnalit√©s AlgorithmLab");
    console.log("   3. Tests manuels des imports transform√©s");
    console.log(
      '   4. Commiter: git add . && git commit -m "Migrate AlgorithmLab to unified architecture"'
    );

    console.log("\nüìä Migration vers architecture unifi√©e r√©ussie:");
    console.log(
      `   üìÅ Point d\'entr√©e: ${
        rules.legacy_compatibility.temporary_aliases
          ? Object.values(rules.legacy_compatibility.temporary_aliases)[0]
              .split("/")
              .slice(0, -1)
              .join("/")
          : "types"
      }`
    );
    console.log("   üìÇ Structure: core/ | algorithms/ | ui/ | utils/");
    console.log("   üîÑ Compatibility: Maintenue avec anciens fichiers");
  } else {
    console.log("\n‚ö†Ô∏è TRANSFORMATION AVEC AVERTISSEMENTS");
    console.log("\nüîß Actions recommand√©es:");
    console.log("   1. Examiner les erreurs dans le log d√©taill√©");
    console.log("   2. V√©rifier manuellement les fichiers probl√©matiques");
    console.log("   3. Corriger si n√©cessaire puis relancer la validation");
    console.log("   4. En cas de probl√®me majeur, rollback depuis les backups");

    if (transformationResults.errors.length > 0) {
      console.log("\n‚ùå Erreurs d√©tect√©es:");
      transformationResults.errors
        .slice(0, 5)
        .forEach((err) => console.log(`   ${err}`));
      if (transformationResults.errors.length > 5) {
        console.log(
          `   ... et ${
            transformationResults.errors.length - 5
          } autres erreurs (voir log)`
        );
      }
    }
  }

  console.log("\nüìñ Documentation de l'architecture unifi√©e:");
  console.log("   üìÑ Voir: migration/audit/accurate-transformation-rules.json");
  console.log("   üìã R√®gles appliqu√©es: Path mappings + Legacy compatibility");
  console.log(
    "   üîÑ Phase suivante: Redistribution optionnelle vers core/algorithms/ui/utils"
  );
}
