# SESSION DE MIGRATION : analysis_pairs - PHASE 4

**Date de dÃ©but Phase 4** : 20 novembre 2025 (aprÃ¨s-midi)  
**DurÃ©e** : ~3h  
**Statut** : âš ï¸ EN COURS - PROBLÃˆME PERFORMANCE CRITIQUE IDENTIFIÃ‰  
**PrioritÃ©** : ğŸ”´ URGENT - Architecture Ã  revoir

---

## ğŸ“Š CONTEXTE - OÃ™ ON EN EST

### âœ… Phases 1-3 ComplÃ¨tes (voir SESSION_MIGRATION_ANALYSIS_PAIRS_FINAL.md)

- Table `analysis_pairs` crÃ©Ã©e et opÃ©rationnelle (901 paires)
- Fonction `refresh_analysis_pairs` fonctionnelle
- Workflow automatique TranscriptLPL â†’ analysis_pairs opÃ©rationnel

### ğŸ”„ Phase 4 : Migration AlgorithmLab

**Objectif** : Migrer l'AlgorithmLab pour utiliser `analysis_pairs` au lieu de `h2_analysis_pairs`

**Progression** :
- âœ… Hook `useAnalysisPairs` crÃ©Ã©
- âœ… Lecture depuis `analysis_pairs` fonctionnelle
- âœ… Transmission du `pairId` dans les mÃ©tadonnÃ©es corrigÃ©e
- âœ… Noms de colonnes X/Y corrigÃ©s
- âœ… RLS policies crÃ©Ã©es (SELECT + UPDATE pour authenticated)
- âœ… Contrainte CHECK `computation_status` corrigÃ©e ('complete' au lieu de 'computed')
- âš ï¸ **BLOQUANT** : Performance catastrophique lors de l'Ã©criture des rÃ©sultats

---

## ğŸ”´ PROBLÃˆME CRITIQUE IDENTIFIÃ‰

### SymptÃ´me

Lors de l'exÃ©cution d'un algorithme (ex: RegexXClassifier) :
- Les 901 paires sont calculÃ©es âœ…
- L'Ã©criture en DB prend **plusieurs minutes** âŒ
- **901 requÃªtes HTTP UPDATE individuelles** au lieu d'une seule requÃªte bulk

### Cause Racine

**Architecture inadaptÃ©e** hÃ©ritÃ©e de l'ancien systÃ¨me :

```typescript
// âŒ ACTUEL : 901 UPDATE individuels
for (const result of results) {
  await supabase
    .from('analysis_pairs')
    .update(updateData)
    .eq('pair_id', pairId);
}
```

**Temps d'exÃ©cution** : 901 Ã— 100ms latence = **~90 secondes**

### Ancien SystÃ¨me (h2_analysis_pairs)

- Ne faisait **PAS** d'UPDATE en base pendant les tests
- Gardait tout en mÃ©moire
- Sauvegarde uniquement Ã  la demande

---

## ğŸ’¡ SOLUTION PROPOSÃ‰E

### Architecture Optimale (RecommandÃ©e)

**Principe** : DÃ©coupler calcul et sauvegarde

#### Ã‰tape 1 : Calculs locaux (en mÃ©moire)

```typescript
const validateAlgorithm = async (algorithmName, sampleSize) => {
  // 1. Calculer les 901 rÃ©sultats (local)
  const results = await runAlgorithm(...);
  
  // 2. Calculer les mÃ©triques (local)
  const metrics = calculateMetrics(results);
  
  // 3. Afficher Ã  l'utilisateur
  // PAS de sauvegarde automatique !
  
  return { results, metrics };
}
```

#### Ã‰tape 2 : Sauvegarde optionnelle (RPC bulk)

```typescript
const saveValidationResults = async (results, algorithmName) => {
  // Appel RPC PostgreSQL qui fait tout cÃ´tÃ© serveur
  const { data, error } = await supabase.rpc(
    'bulk_update_algorithm_results',
    {
      pairs_data: results.map(r => ({
        pair_id: r.metadata.pairId,
        x_predicted_tag: r.predicted,
        x_confidence: r.confidence,
        // ...
      })),
      algorithm_name: algorithmName,
      algorithm_version: version
    }
  );
}
```

#### Ã‰tape 3 : Fonction RPC PostgreSQL

```sql
CREATE OR REPLACE FUNCTION bulk_update_algorithm_results(
  pairs_data jsonb,
  algorithm_name text,
  algorithm_version text
)
RETURNS json AS $$
DECLARE
  updated_count int := 0;
  pair_record jsonb;
BEGIN
  -- ItÃ©rer sur le tableau JSON
  FOR pair_record IN SELECT * FROM jsonb_array_elements(pairs_data)
  LOOP
    UPDATE analysis_pairs
    SET 
      x_predicted_tag = (pair_record->>'x_predicted_tag'),
      x_confidence = (pair_record->>'x_confidence')::numeric,
      x_algorithm_key = algorithm_name,
      x_algorithm_version = algorithm_version,
      x_computed_at = now(),
      computation_status = 'complete',
      updated_at = now()
    WHERE pair_id = (pair_record->>'pair_id')::bigint;
    
    IF FOUND THEN
      updated_count := updated_count + 1;
    END IF;
  END LOOP;
  
  RETURN json_build_object(
    'success', true,
    'updated', updated_count
  );
END;
$$ LANGUAGE plpgsql;
```

**Avantages** :
- âš¡ Ultra-rapide (< 1 seconde pour 901 paires)
- ğŸ§ª Tests rapides sans polluer la DB
- ğŸ’¾ Sauvegarde uniquement si rÃ©sultats satisfaisants
- ğŸ¯ Architecture scientifique correcte

---

## ğŸ“ FICHIERS MODIFIÃ‰S AUJOURD'HUI

### Fichiers principaux

1. **src/features/phase3-analysis/level1-validation/ui/hooks/useLevel1Testing.ts**
   - âŒ Ligne 199-200 : Colonnes gÃ©nÃ©riques supprimÃ©es
   - âœ… Ligne 223-229 : Noms colonnes X/Y corrigÃ©s
   - âœ… Ligne 185-276 : Fonction `updateH2WithResults` (mais TROP LENTE)
   - âš ï¸ **Ã€ MODIFIER** : DÃ©coupler calcul/sauvegarde

2. **src/features/phase3-analysis/level1-validation/ui/hooks/normalizeUniversalToTV.ts**
   - âœ… Ligne 36 : `pairId` ajoutÃ© dans `baseMd`

3. **Base de donnÃ©es Supabase**
   - âœ… RLS policies crÃ©Ã©es pour `analysis_pairs`
   - âœ… Contrainte CHECK `computation_status` validÃ©e

### ProblÃ¨mes rÃ©solus

| ProblÃ¨me | Solution | Status |
|----------|----------|--------|
| pairId manquant | Ajout dans normalizeUniversalToTV.ts | âœ… |
| Colonnes computed_at/algorithm_version | Suppression (n'existent pas) | âœ… |
| Colonnes X et Y mÃ©langÃ©es | SÃ©paration X / Y | âœ… |
| RLS bloque UPDATE | Policies crÃ©Ã©es | âœ… |
| CHECK constraint violated | 'computed' â†’ 'complete' | âœ… |
| 901 UPDATE individuels | **âš ï¸ EN ATTENTE DE SOLUTION** | âŒ |

---

## ğŸ¯ PLAN D'ACTION - PROCHAINE SESSION (PRIORITÃ‰)

### â­ Option B : Bulk upsert simple (Ã€ FAIRE EN PREMIER - 30 min)

**Pourquoi commencer par Option B ?**
- Plus rapide Ã  implÃ©menter (30 min vs 2h)
- Garde l'architecture actuelle (moins de risques)
- RÃ©sout immÃ©diatement le problÃ¨me de performance
- On peut passer Ã  Option A plus tard si besoin

#### Task 1 : Modifier updateH2WithResults pour utiliser .upsert() (20 min)

**Fichier** : `src/features/phase3-analysis/level1-validation/ui/hooks/useLevel1Testing.ts`

**Fonction Ã  remplacer** : Lignes 183-276

**ANCIEN CODE (901 UPDATE individuels)** :
```typescript
const updateH2WithResults = async (
  results: TVValidationResult[],
  algorithmName: string,
  algorithmVersion: string
): Promise<{ success: number; errors: number; total: number }> => {
  console.log(`ğŸ“ Mise Ã  jour analysis_pairs : ${results.length} paires`);
  
  let successCount = 0;
  let errorCount = 0;

  for (const result of results) {
    const pairId = getH2Property(result.metadata, 'pairId');
    
    if (!pairId) {
      console.warn('âš ï¸ Pas de pairId:', result);
      errorCount++;
      continue;
    }

    const updateData: any = {};

    try {
      // Remplir selon l'algo
      if (algorithmName.includes('M1')) {
        updateData.m1_verb_density = getH2Property(result.metadata, 'm1_verb_density');
        updateData.m1_verb_count = getH2Property(result.metadata, 'm1_verb_count');
        updateData.m1_total_words = getH2Property(result.metadata, 'm1_total_words');
        updateData.m1_action_verbs = getH2Property(result.metadata, 'm1_action_verbs');
        updateData.computation_status = 'complete';
      } else if (algorithmName.includes('M2')) {
        // ...
      } else if (algorithmName.includes('M3')) {
        // ...
      } else if (algorithmName.includes('X')) {
        updateData.x_predicted_tag = result.predicted;
        updateData.x_confidence = result.confidence;
        updateData.x_algorithm_key = algorithmName;
        updateData.x_algorithm_version = algorithmVersion;
        updateData.x_computed_at = new Date().toISOString();
        updateData.computation_status = 'complete';
      }

      // âŒ PROBLÃˆME : 901 UPDATE individuels
      console.log('ğŸ” UPDATE DATA:', { pairId, updateData });
      
      let success = false;
      let lastError: any = null;

      for (let attempt = 0; attempt <= MAX_RETRIES && !success; attempt++) {
        try {
          const { error } = await supabase
            .from('analysis_pairs')
            .update(updateData)
            .eq('pair_id', pairId);  // â† Une requÃªte par paire !

          if (error) { console.error('âŒ SUPABASE ERROR:', error); throw error; }
          success = true;
          successCount++;
        } catch (err) {
          lastError = err;
          if (attempt < MAX_RETRIES) {
            await new Promise(resolve => setTimeout(resolve, 500 * (attempt + 1)));
          }
        }
      }

      if (!success) {
        errorCount++;
        // ...
      }
    } catch (err) {
      errorCount++;
      console.error(`âŒ Erreur pair_id=${pairId}:`, err);
    }
  }

  console.log(`âœ… ${successCount} paires mises Ã  jour, âŒ ${errorCount} erreurs`);
  return { success: successCount, errors: errorCount, total: results.length };
};
```

**NOUVEAU CODE (1 seul UPSERT pour toutes les paires)** :
```typescript
const updateH2WithResults = async (
  results: TVValidationResult[],
  algorithmName: string,
  algorithmVersion: string
): Promise<{ success: number; errors: number; total: number }> => {
  console.log(`ğŸ“ Mise Ã  jour analysis_pairs : ${results.length} paires (BULK UPSERT)`);
  
  const bulkData: any[] = [];
  let skipped = 0;

  // PrÃ©parer les donnÃ©es pour bulk upsert
  for (const result of results) {
    const pairId = getH2Property(result.metadata, 'pairId');
    
    if (!pairId) {
      console.warn('âš ï¸ Pas de pairId:', result);
      skipped++;
      continue;
    }

    const row: any = { pair_id: pairId };

    // Remplir selon l'algo
    if (algorithmName.includes('M1')) {
      row.m1_verb_density = getH2Property(result.metadata, 'm1_verb_density');
      row.m1_verb_count = getH2Property(result.metadata, 'm1_verb_count');
      row.m1_total_words = getH2Property(result.metadata, 'm1_total_words');
      row.m1_action_verbs = getH2Property(result.metadata, 'm1_action_verbs');
      row.computation_status = 'complete';
    } else if (algorithmName.includes('M2')) {
      row.m2_lexical_alignment = getH2Property(result.metadata, 'm2_lexical_alignment');
      row.m2_semantic_alignment = getH2Property(result.metadata, 'm2_semantic_alignment');
      row.m2_global_alignment = getH2Property(result.metadata, 'm2_global_alignment');
      row.m2_shared_terms = getH2Property(result.metadata, 'm2_shared_terms');
      row.computation_status = 'complete';
    } else if (algorithmName.includes('M3')) {
      row.m3_hesitation_count = getH2Property(result.metadata, 'm3_hesitation_count');
      row.m3_clarification_count = getH2Property(result.metadata, 'm3_clarification_count');
      row.m3_cognitive_score = getH2Property(result.metadata, 'm3_cognitive_score');
      row.m3_cognitive_load = getH2Property(result.metadata, 'm3_cognitive_load');
      row.m3_patterns = getH2Property(result.metadata, 'm3_patterns');
      row.computation_status = 'complete';
    } else if (algorithmName.includes('X')) {
      row.x_predicted_tag = result.predicted;
      row.x_confidence = result.confidence;
      row.x_algorithm_key = algorithmName;
      row.x_algorithm_version = algorithmVersion;
      row.x_computed_at = new Date().toISOString();
      row.computation_status = 'complete';
    } else if (algorithmName.includes('Y')) {
      row.y_predicted_tag = result.predicted;
      row.y_confidence = result.confidence;
      row.y_algorithm_key = algorithmName;
      row.y_algorithm_version = algorithmVersion;
      row.y_computed_at = new Date().toISOString();
      row.computation_status = 'complete';
    }

    bulkData.push(row);
  }

  if (bulkData.length === 0) {
    console.error('âŒ Aucune donnÃ©e Ã  sauvegarder');
    return { success: 0, errors: results.length, total: results.length };
  }

  // âœ… UN SEUL UPSERT pour toutes les paires
  try {
    console.log(`ğŸš€ BULK UPSERT: ${bulkData.length} lignes...`);
    const startTime = Date.now();
    
    const { error, count } = await supabase
      .from('analysis_pairs')
      .upsert(bulkData, { 
        onConflict: 'pair_id',
        count: 'exact'
      });

    const duration = Date.now() - startTime;

    if (error) {
      console.error('âŒ ERREUR BULK UPSERT:', error);
      throw error;
    }

    const successCount = count || bulkData.length;
    console.log(`âœ… ${successCount} paires mises Ã  jour en ${duration}ms`);
    console.log(`â±ï¸  Performance: ${Math.round(successCount / (duration / 1000))} paires/seconde`);
    
    return { 
      success: successCount, 
      errors: skipped, 
      total: results.length 
    };
  } catch (error) {
    console.error('âŒ Erreur critique:', error);
    return { 
      success: 0, 
      errors: results.length, 
      total: results.length 
    };
  }
};
```

**Commande PowerShell pour appliquer** :
```powershell
# CrÃ©er un backup d'abord
Copy-Item "src\features\phase3-analysis\level1-validation\ui\hooks\useLevel1Testing.ts" "src\features\phase3-analysis\level1-validation\ui\hooks\useLevel1Testing.ts.backup_bulk"

# Ensuite remplacer la fonction (utiliser str_replace ou Ã©diteur)
```

#### Task 2 : Supprimer les logs de debug (5 min)

**Supprimer ces lignes** :
```typescript
console.log('ğŸ” UPDATE DATA:', { pairId, updateData }); // N'existe plus dans nouveau code
console.error('âŒ SUPABASE ERROR:', error); // N'existe plus dans nouveau code
```

Ces logs Ã©taient pour le debugging, ils ne sont plus nÃ©cessaires avec le bulk upsert.

#### Task 3 : Tester (5 min)

1. Ouvrir AlgorithmLab : `/phase3-analysis/level1/algorithm-lab`
2. SÃ©lectionner "RegexXClassifier"
3. Cliquer "Lancer le test"
4. **VÃ©rifier dans la console** :
   - `ğŸš€ BULK UPSERT: 901 lignes...`
   - `âœ… 901 paires mises Ã  jour en XXXms` (devrait Ãªtre < 2000ms)
   - `â±ï¸ Performance: XXX paires/seconde`

5. **VÃ©rifier en DB** :
```sql
SELECT COUNT(*) FROM analysis_pairs WHERE x_predicted_tag IS NOT NULL;
-- Attendu : 901
```

**Performance attendue** : < 2 secondes pour 901 paires (vs 90 secondes avant)

---

### Option A : Architecture dÃ©couplÃ©e (Ã€ faire plus tard si nÃ©cessaire - 2h)

#### Task 1 : CrÃ©er la fonction RPC (30 min)

```sql
-- Fichier : supabase/functions/bulk_update_algorithm_results.sql
CREATE OR REPLACE FUNCTION bulk_update_algorithm_results(
  pairs_data jsonb,
  algorithm_name text,
  algorithm_version text
)
RETURNS json AS $$
-- (voir code complet ci-dessus)
```

**Commande SQL** : ExÃ©cuter dans Supabase SQL Editor

#### Task 2 : Modifier useLevel1Testing.ts (45 min)

**2.1 Supprimer l'appel automatique Ã  updateH2WithResults**

Ligne 491 actuelle :
```typescript
await updateH2WithResults(tvRows, classifierName, version);
```

Devient :
```typescript
// Ne plus sauvegarder automatiquement
// L'utilisateur dÃ©cidera via bouton "Sauvegarder"
```

**2.2 CrÃ©er une nouvelle fonction saveResults**

```typescript
const saveResults = useCallback(
  async (
    results: TVValidationResult[],
    algorithmName: string
  ): Promise<{ success: boolean; updated: number }> => {
    const pairsData = results.map(r => ({
      pair_id: getH2Property(r.metadata, 'pairId'),
      x_predicted_tag: r.predicted,
      x_confidence: r.confidence,
    }));

    const { data, error } = await supabase.rpc(
      'bulk_update_algorithm_results',
      {
        pairs_data: pairsData,
        algorithm_name: algorithmName,
        algorithm_version: `${algorithmName}_v${new Date().toISOString().split('T')[0]}`
      }
    );

    if (error) throw error;
    return data;
  },
  []
);
```

**2.3 Exporter saveResults**

```typescript
return {
  // ... autres exports
  saveResults,  // â† NOUVEAU
};
```

#### Task 3 : Ajouter bouton "Sauvegarder" dans l'UI (45 min)

**Fichier** : `src/features/phase3-analysis/level1-validation/ui/components/shared/BaseAlgorithmTesting.tsx`

**Localisation** : AprÃ¨s l'affichage des rÃ©sultats (ligne ~200)

```typescript
{results && results.length > 0 && (
  <Button
    variant="contained"
    color="primary"
    onClick={handleSaveResults}
    disabled={isSaving}
  >
    {isSaving ? 'Sauvegarde...' : 'Sauvegarder les rÃ©sultats'}
  </Button>
)}
```

**Handler** :
```typescript
const [isSaving, setIsSaving] = useState(false);

const handleSaveResults = async () => {
  setIsSaving(true);
  try {
    const result = await saveResults(
      results,
      selectedAlgorithm
    );
    
    console.log(`âœ… ${result.updated} paires sauvegardÃ©es`);
    // Afficher notification succÃ¨s
  } catch (error) {
    console.error('âŒ Erreur sauvegarde:', error);
    // Afficher notification erreur
  } finally {
    setIsSaving(false);
  }
};
```

### Option B : Bulk upsert simple (Plus rapide - 30 min)

Si vous voulez garder la sauvegarde automatique mais l'optimiser :

**Modifier updateH2WithResults** pour utiliser `.upsert()` au lieu de boucle :

```typescript
const updateH2WithResults = async (
  results: TVValidationResult[],
  algorithmName: string,
  algorithmVersion: string
) => {
  const bulkData = results.map(result => ({
    pair_id: getH2Property(result.metadata, 'pairId'),
    x_predicted_tag: result.predicted,
    x_confidence: result.confidence,
    x_algorithm_key: algorithmName,
    x_algorithm_version: algorithmVersion,
    x_computed_at: new Date().toISOString(),
    computation_status: 'complete'
  }));

  const { error, count } = await supabase
    .from('analysis_pairs')
    .upsert(bulkData, { onConflict: 'pair_id' });

  if (error) throw error;
  return { success: count || 0, errors: 0, total: results.length };
};
```

**Avantage** : Plus simple, garde l'architecture actuelle
**InconvÃ©nient** : Pas optimal scientifiquement (sauvegarde Ã  chaque test)

---

## ğŸ§ª TESTS Ã€ EFFECTUER

### Test 1 : Fonction RPC

```sql
-- CrÃ©er donnÃ©es de test
SELECT bulk_update_algorithm_results(
  '[
    {"pair_id": 3788, "x_predicted_tag": "ENGAGEMENT", "x_confidence": 0.85},
    {"pair_id": 3789, "x_predicted_tag": "EXPLICATION", "x_confidence": 0.72}
  ]'::jsonb,
  'RegexXClassifier',
  'test_v2025-11-20'
);

-- VÃ©rifier rÃ©sultat
SELECT pair_id, x_predicted_tag, x_confidence, x_algorithm_key 
FROM analysis_pairs 
WHERE pair_id IN (3788, 3789);
```

**RÃ©sultat attendu** : Les 2 paires doivent Ãªtre mises Ã  jour

### Test 2 : Workflow complet

1. Ouvrir AlgorithmLab : `/phase3-analysis/level1/algorithm-lab`
2. SÃ©lectionner "RegexXClassifier"
3. Cliquer "Lancer le test"
4. **Attendre calcul** (doit Ãªtre rapide - < 10 secondes)
5. **VÃ©rifier mÃ©triques affichÃ©es** (accuracy, precision, etc.)
6. Cliquer "Sauvegarder les rÃ©sultats"
7. **VÃ©rifier sauvegarde** (doit Ãªtre ultra-rapide - < 1 seconde)

### Test 3 : Validation DB

```sql
-- Compter rÃ©sultats X
SELECT COUNT(*) FROM analysis_pairs WHERE x_predicted_tag IS NOT NULL;
-- Attendu : 901

-- VÃ©rifier derniÃ¨re mise Ã  jour
SELECT x_algorithm_key, x_algorithm_version, COUNT(*) 
FROM analysis_pairs 
WHERE x_computed_at > now() - interval '1 hour'
GROUP BY x_algorithm_key, x_algorithm_version;
```

---

## ğŸ“š CONTEXTE TECHNIQUE COMPLET

### Structure de `analysis_pairs`

**Colonnes principales** :
- `pair_id` (BIGSERIAL PRIMARY KEY) - Identifiant unique
- `call_id` (TEXT) - Identifiant appel
- `conseiller_turn_id` / `client_turn_id` (INTEGER) - IDs des tours
- `strategy_tag` / `reaction_tag` (TEXT) - Tags manuels (gold standard)
- `conseiller_verbatim` / `client_verbatim` (TEXT) - Textes

**Colonnes algorithme X** (conseiller) :
- `x_predicted_tag` (TEXT) - PrÃ©diction
- `x_confidence` (NUMERIC) - Score de confiance
- `x_algorithm_key` (TEXT) - Nom algorithme
- `x_algorithm_version` (TEXT) - Version
- `x_computed_at` (TIMESTAMP) - Date calcul

**Colonnes algorithme Y** (client) :
- `y_predicted_tag`, `y_confidence`, `y_algorithm_key`, etc.

**Colonnes mÃ©diateurs** :
- `m1_*` (densitÃ© verbes d'action)
- `m2_*` (alignement linguistique)
- `m3_*` (charge cognitive)

**Colonne de statut** :
- `computation_status` (TEXT) - CHECK ('pending', 'partial', 'complete', 'error')

### Workflow algorithme actuel

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. useAnalysisPairs()                       â”‚
â”‚    Charge les 901 paires depuis DB          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. mapH2ToGoldStandard()                    â”‚
â”‚    Transforme en GoldStandardSample[]       â”‚
â”‚    Ajoute metadata.pairId                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. validateAlgorithm()                      â”‚
â”‚    - Filtre corpus selon algo               â”‚
â”‚    - PrÃ©pare inputs                         â”‚
â”‚    - ExÃ©cute classifier.run()               â”‚
â”‚    - Normalise rÃ©sultats                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. normalizeUniversalToTV()                 â”‚
â”‚    - Combine rÃ©sultat algo + metadata       â”‚
â”‚    - Transmet pairId dans result.metadata   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. updateH2WithResults() âš ï¸ BLOQUANT        â”‚
â”‚    - 901 UPDATE individuels                 â”‚
â”‚    - Temps : ~90 secondes                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Fichiers clÃ©s

| Fichier | RÃ´le | Lignes importantes |
|---------|------|-------------------|
| `useLevel1Testing.ts` | Hook principal validation | 185-276 (updateH2WithResults) |
| `useAnalysisPairs.ts` | Lecture analysis_pairs | Tout le fichier |
| `normalizeUniversalToTV.ts` | Normalisation rÃ©sultats | 36 (pairId) |
| `BaseAlgorithmTesting.tsx` | Interface UI | 167 (runValidation) |
| `RegexXClassifier.ts` | Exemple algorithme | run() method |

---

## ğŸ“ DÃ‰CISIONS CLÃ‰S PRISES

### 1. Pourquoi dÃ©coupler calcul/sauvegarde ?

**Raison scientifique** : 
- Les chercheurs testent souvent 10-20 variantes d'algorithmes
- Polluer la DB Ã  chaque test n'est pas pertinent
- Seuls les rÃ©sultats validÃ©s doivent Ãªtre sauvegardÃ©s

**Raison technique** :
- 901 UPDATE = trop lent
- Calculs locaux = instantanÃ©s
- Sauvegarde bulk RPC = < 1 seconde

### 2. Pourquoi RPC plutÃ´t que .upsert() ?

**Avantages RPC** :
- ExÃ©cution cÃ´tÃ© serveur (plus rapide)
- Pas de limite de taille requÃªte HTTP
- PossibilitÃ© d'ajouter logique mÃ©tier (validations, logs)
- Une seule transaction atomique

**Limitations .upsert()** :
- Limite taille payload HTTP (~6MB)
- ExÃ©cution cÃ´tÃ© client (sÃ©rialisation JSON)
- Pas de logique mÃ©tier

### 3. Pourquoi pas de sauvegarde auto ?

L'ancien systÃ¨me (`h2_analysis_pairs`) ne faisait PAS de sauvegarde automatique. C'Ã©tait volontaire. On reproduit ce comportement optimal.

---

## âš ï¸ POINTS D'ATTENTION

### 1. Logs de debug Ã  supprimer

**Fichier** : `useLevel1Testing.ts`

**Lignes Ã  supprimer aprÃ¨s tests** :
```typescript
console.log('ğŸ” UPDATE DATA:', { pairId, updateData }); // Ligne 236
console.error('âŒ SUPABASE ERROR:', error); // Ligne 245
```

### 2. RLS Policies

Les policies actuelles sont **trÃ¨s permissives** :

```sql
CREATE POLICY "Allow authenticated users to update analysis_pairs"
ON analysis_pairs FOR UPDATE TO authenticated
USING (true) WITH CHECK (true);
```

**Ã€ amÃ©liorer** si besoin de sÃ©curitÃ© par entreprise/utilisateur :

```sql
-- Exemple : Restreindre par entreprise
USING (
  call_id IN (
    SELECT CAST(callid AS text) FROM call c
    INNER JOIN entreprise_call ec ON c.callid = ec.callid
    WHERE ec.identreprise = current_user_entreprise_id()
  )
)
```

### 3. Validation des donnÃ©es

La fonction RPC devrait valider :
- `pair_id` existe
- `x_predicted_tag` est une valeur valide
- `x_confidence` est entre 0 et 1

---

## ğŸ“‹ CHECKLIST AVANT COMMIT

- [ ] Fonction RPC `bulk_update_algorithm_results` crÃ©Ã©e et testÃ©e
- [ ] `useLevel1Testing.ts` modifiÃ© (saveResults ajoutÃ©e)
- [ ] `BaseAlgorithmTesting.tsx` modifiÃ© (bouton Sauvegarder)
- [ ] Logs de debug supprimÃ©s
- [ ] Tests validation passÃ©s (901 paires)
- [ ] Documentation mise Ã  jour
- [ ] Commit avec message descriptif

---

## ğŸš€ COMMANDES GIT

```powershell
# Voir les fichiers modifiÃ©s
git status

# Ajouter les modifications
git add src/features/phase3-analysis/level1-validation/ui/hooks/useLevel1Testing.ts
git add src/features/phase3-analysis/level1-validation/ui/hooks/normalizeUniversalToTV.ts
git add src/features/phase3-analysis/level1-validation/ui/components/shared/BaseAlgorithmTesting.tsx

# Commit avec message descriptif
git commit -m "feat(phase3): Optimiser sauvegarde rÃ©sultats algorithmes

- CrÃ©er fonction RPC bulk_update_algorithm_results pour UPDATE en masse
- DÃ©coupler calcul (local) et sauvegarde (optionnelle)
- Ajouter bouton Sauvegarder dans BaseAlgorithmTesting
- Corriger transmission pairId dans normalizeUniversalToTV
- Corriger noms colonnes X/Y et computation_status
- Performance : 901 paires en < 1 seconde (vs 90 secondes avant)

BREAKING CHANGE: Les rÃ©sultats ne sont plus sauvegardÃ©s automatiquement.
L'utilisateur doit cliquer sur 'Sauvegarder les rÃ©sultats'."
```

---

## ğŸ“ POUR LA PROCHAINE SESSION

### ğŸ¯ Phrase d'accroche pour Claude

> "Nous sommes en Phase 4 de la migration analysis_pairs. ProblÃ¨me de performance rÃ©solu par identification de la cause (901 UPDATE individuels). Nous allons implÃ©menter Option B : bulk upsert en une seule requÃªte. DurÃ©e estimÃ©e : 30 minutes. Voir SESSION_MIGRATION_ANALYSIS_PAIRS_PHASE4.md section 'PLAN D'ACTION - Option B'."

### ğŸ“š Documents ESSENTIELS Ã  fournir Ã  Claude (dans l'ordre)

#### 1. **SESSION_MIGRATION_ANALYSIS_PAIRS_PHASE4.md** â­ CRITIQUE
**Pourquoi** : Document vivant avec TOUT le contexte actuel
**Sections clÃ©s** :
- Ã‰tat actuel (Phase 4 en cours)
- ProblÃ¨me identifiÃ© (901 UPDATE individuels)
- Solution Option B (code complet)
- Fichiers modifiÃ©s
- Tests Ã  effectuer

#### 2. **schema.sql** â­ CRITIQUE
**Pourquoi** : Structure exacte de la table `analysis_pairs`
**Info clÃ©** : 
- Noms des colonnes X/Y/M1/M2/M3
- Contrainte CHECK sur `computation_status` : ('pending', 'partial', 'complete', 'error')
- Contrainte PRIMARY KEY sur `pair_id`

**Sections importantes** :
```sql
CREATE TABLE public.analysis_pairs (
  pair_id bigint NOT NULL DEFAULT nextval('analysis_pairs_pair_id_seq'::regclass),
  -- ... colonnes X
  x_predicted_tag text,
  x_confidence numeric,
  x_algorithm_key text,
  x_algorithm_version text,
  x_computed_at timestamp without time zone,
  -- ... colonnes Y
  y_predicted_tag text,
  y_confidence numeric,
  -- ... computation_status avec CHECK constraint
  computation_status text DEFAULT 'pending'::text 
    CHECK (computation_status = ANY (ARRAY['pending'::text, 'partial'::text, 'complete'::text, 'error'::text])),
  CONSTRAINT analysis_pairs_pkey PRIMARY KEY (pair_id)
);
```

#### 3. **RECAPITULATIF_FONCTIONNEMENT_ALGORITHMES.md** (si crÃ©Ã© aujourd'hui)
**Pourquoi** : Explique le flow complet des algorithmes
**Info clÃ©** :
- Comment les donnÃ©es circulent
- OÃ¹ le `pairId` est transmis
- RÃ´le de `normalizeUniversalToTV`

#### 4. âš ï¸ Documents Ã  NE PAS fournir (pour Ã©viter confusion)

**âŒ SESSION_MIGRATION_ANALYSIS_PAIRS_FINAL.md**
- Concerne Phases 1-3 (terminÃ©es)
- Peut crÃ©er confusion avec Phase 4

**âŒ ARCHITECTURE_CIBLE_WORKFLOW.md**
- Trop gÃ©nÃ©ral, pas spÃ©cifique au problÃ¨me actuel

**âŒ Code de l'ancien systÃ¨me (h2_analysis_pairs)**
- On ne travaille PLUS avec h2_analysis_pairs
- Risque de confusion

### ğŸ“‚ Fichiers Ã  avoir sous les yeux

**Fichier principal Ã  modifier** :
```
src/features/phase3-analysis/level1-validation/ui/hooks/useLevel1Testing.ts
```

**Lignes critiques** :
- 183-276 : Fonction `updateH2WithResults` (Ã€ REMPLACER)
- 491 : Appel Ã  `updateH2WithResults` (ne pas toucher, fonctionne dÃ©jÃ )

**Fichier de rÃ©fÃ©rence** :
```
src/features/phase3-analysis/level1-validation/ui/hooks/normalizeUniversalToTV.ts
```
- Ligne 36 : `pairId` est bien transmis âœ…

### ğŸ” Commandes PowerShell utiles

```powershell
# Localiser le fichier Ã  modifier
Get-ChildItem -Recurse -Filter "useLevel1Testing.ts" | Where-Object { $_.FullName -like "*phase3-analysis*" } | Select-Object FullName

# CrÃ©er backup avant modification
Copy-Item "src\features\phase3-analysis\level1-validation\ui\hooks\useLevel1Testing.ts" "src\features\phase3-analysis\level1-validation\ui\hooks\useLevel1Testing.ts.backup_bulk"

# Voir la fonction actuelle
Get-Content "src\features\phase3-analysis\level1-validation\ui\hooks\useLevel1Testing.ts" | Select-Object -Index 183,184,185,186,187,188,189,190

# AprÃ¨s modification, vÃ©rifier .upsert()
Get-Content "src\features\phase3-analysis\level1-validation\ui\hooks\useLevel1Testing.ts" | Select-String "\.upsert\("
```

### âš ï¸ Points d'attention pour Claude

#### 1. Ne PAS modifier ces parties
- âœ… `normalizeUniversalToTV.ts` : Le `pairId` est dÃ©jÃ  correctement transmis
- âœ… Ligne 491 : L'appel Ã  `updateH2WithResults` fonctionne dÃ©jÃ 
- âœ… `useAnalysisPairs.ts` : La lecture fonctionne bien

#### 2. UNIQUEMENT modifier
- ğŸ¯ Fonction `updateH2WithResults` (lignes 183-276)
- ğŸ¯ Remplacer la boucle `for` + 901 UPDATE par 1 seul `.upsert()`

#### 3. Erreurs Ã  Ã©viter

**âŒ NE PAS faire** :
```typescript
// ERREUR : Oublier onConflict
.upsert(bulkData) // âŒ Va crÃ©er des doublons

// ERREUR : Mauvais nom de conflit
.upsert(bulkData, { onConflict: 'id' }) // âŒ La colonne s'appelle 'pair_id'

// ERREUR : Oublier computation_status
row.x_predicted_tag = result.predicted;
// âŒ Manque row.computation_status = 'complete'
```

**âœ… FAIRE** :
```typescript
.upsert(bulkData, { 
  onConflict: 'pair_id',  // âœ… Nom correct
  count: 'exact'          // âœ… Pour avoir le nombre de lignes affectÃ©es
});

// âœ… Toujours inclure computation_status
row.computation_status = 'complete';
```

#### 4. Validation aprÃ¨s modification

**Console du navigateur doit afficher** :
```
ğŸ“ Mise Ã  jour analysis_pairs : 901 paires (BULK UPSERT)
ğŸš€ BULK UPSERT: 901 lignes...
âœ… 901 paires mises Ã  jour en 1523ms
â±ï¸ Performance: 591 paires/seconde
```

**Si erreur 400 Bad Request** :
- VÃ©rifier `computation_status = 'complete'` (pas 'computed')
- VÃ©rifier `onConflict: 'pair_id'` (pas 'id')
- VÃ©rifier que `pair_id` est bien dans chaque `row`

### ğŸ“ Contexte algorithmique (rappel rapide)

**Les 5 types d'algorithmes** :
- **X** : Classifie le conseiller (ENGAGEMENT, OUVERTURE, REFLET_*, EXPLICATION)
- **Y** : Classifie le client (CLIENT_POSITIF, CLIENT_NEUTRE, CLIENT_NEGATIF)
- **M1** : Compte les verbes d'action (mÃ©diateur)
- **M2** : Mesure l'alignement linguistique (mÃ©diateur)
- **M3** : Ã‰value la charge cognitive (mÃ©diateur)

**Colonnes DB par algorithme** :
```
X â†’ x_predicted_tag, x_confidence, x_algorithm_key, x_algorithm_version, x_computed_at
Y â†’ y_predicted_tag, y_confidence, y_algorithm_key, y_algorithm_version, y_computed_at
M1 â†’ m1_verb_density, m1_verb_count, m1_total_words, m1_action_verbs
M2 â†’ m2_lexical_alignment, m2_semantic_alignment, m2_global_alignment, m2_shared_terms
M3 â†’ m3_hesitation_count, m3_clarification_count, m3_cognitive_score, m3_cognitive_load
```

### ğŸ“‹ Checklist avant de commencer

**Contexte confirmÃ©** :
- [ ] Phase 4 migration en cours
- [ ] ProblÃ¨me : 901 UPDATE individuels (trop lent)
- [ ] Solution : Option B bulk upsert
- [ ] Fichier Ã  modifier : `useLevel1Testing.ts` lignes 183-276

**Documents fournis** :
- [ ] SESSION_MIGRATION_ANALYSIS_PAIRS_PHASE4.md
- [ ] schema.sql (structure analysis_pairs)
- [ ] RECAPITULATIF_FONCTIONNEMENT_ALGORITHMES.md (optionnel)

**PrÃªt Ã  dÃ©marrer** :
- [ ] Backup crÃ©Ã© : `useLevel1Testing.ts.backup_bulk`
- [ ] Nouveau code bulk upsert sous les yeux
- [ ] 30 minutes disponibles

---

**DerniÃ¨re mise Ã  jour** : 20 novembre 2025 - 18h10  
**Prochaine Ã©tape** : ImplÃ©menter architecture dÃ©couplÃ©e (Option A - 2h)  
**Fichier vivant** : Ã€ mettre Ã  jour aprÃ¨s chaque session
