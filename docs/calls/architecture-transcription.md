# üéôÔ∏è Architecture de Transcription & Diarisation

> Architecture DDD rationalis√©e pour la transcription automatique avec segmentation et diarisation

## üìã Table des Mati√®res

- [Vue d&#39;ensemble](https://claude.ai/chat/cbd80c4e-8905-4710-bef4-536cde9675a3#vue-densemble)
- [Architecture Globale](https://claude.ai/chat/cbd80c4e-8905-4710-bef4-536cde9675a3#architecture-globale)
- [Flow Chart D√©taill√©](https://claude.ai/chat/cbd80c4e-8905-4710-bef4-536cde9675a3#flow-chart-d%C3%A9taill%C3%A9)
- [Composants Principaux](https://claude.ai/chat/cbd80c4e-8905-4710-bef4-536cde9675a3#composants-principaux)
- [API Routes](https://claude.ai/chat/cbd80c4e-8905-4710-bef4-536cde9675a3#api-routes)
- [Services Domain](https://claude.ai/chat/cbd80c4e-8905-4710-bef4-536cde9675a3#services-domain)
- [Flux de Donn√©es](https://claude.ai/chat/cbd80c4e-8905-4710-bef4-536cde9675a3#flux-de-donn%C3%A9es)
- [Exemples d&#39;Usage](https://claude.ai/chat/cbd80c4e-8905-4710-bef4-536cde9675a3#exemples-dusage)
- [Migration depuis l&#39;Ancienne Architecture](https://claude.ai/chat/cbd80c4e-8905-4710-bef4-536cde9675a3#migration)

## üéØ Vue d'ensemble

Cette architecture moderne remplace l'ancien syst√®me hybride par une approche **Domain-Driven Design** pure avec :

- ‚úÖ **API Routes directes** vers OpenAI/AssemblyAI
- ‚úÖ **Segments temporels** pour synchronisation ASR ‚Üî Diarisation
- ‚úÖ **Services Domain** avec logique m√©tier isol√©e
- ‚úÖ **Gestion d'erreurs** granulaire par stage
- ‚úÖ **S√©curit√©** avec cl√©s API c√¥t√© serveur uniquement

## üèóÔ∏è Architecture Globale

```mermaid
graph TD
    UI[Interface Utilisateur] --> DS[Domain Services]
    DS --> AC[API Clients]
    AC --> TR[/api/calls/transcribe]
    AC --> DR[/api/calls/diarize]
    TR --> OpenAI[OpenAI API]
    DR --> AssemblyAI[AssemblyAI API]
```

### Architecture en Couches

````
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ           CLIENT (Browser)          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ Interface Utilisateur       ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ Domain Services            ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ - TranscriptionASRService   ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ - TranscriptionIntegration  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ - DiarizationService        ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ API Clients                 ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ - TranscriptionApiClient    ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ - DiarizationApiClient      ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                  ‚Üì HTTP
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ           SERVER (Next.js)          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ API Routes                  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ - /api/calls/transcribe     ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ - /api/calls/diarize        ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                  ‚Üì HTTPS# üéôÔ∏è Architecture de Transcription & Diarisation

> Architecture DDD rationalis√©e pour la transcription automatique avec segmentation et diarisation

## üìã Table des Mati√®res

- [Vue d'ensemble](#vue-densemble)
- [Architecture Globale](#architecture-globale)
- [Flow Chart D√©taill√©](#flow-chart-d√©taill√©)
- [Composants Principaux](#composants-principaux)
- [API Routes](#api-routes)
- [Services Domain](#services-domain)
- [Flux de Donn√©es](#flux-de-donn√©es)
- [Exemples d'Usage](#exemples-dusage)
- [Migration depuis l'Ancienne Architecture](#migration)

## üéØ Vue d'ensemble

Cette architecture moderne remplace l'ancien syst√®me hybride par une approche **Domain-Driven Design** pure avec :

- ‚úÖ **API Routes directes** vers OpenAI/AssemblyAI
- ‚úÖ **Segments temporels** pour synchronisation ASR ‚Üî Diarisation
- ‚úÖ **Services Domain** avec logique m√©tier isol√©e
- ‚úÖ **Gestion d'erreurs** granulaire par stage
- ‚úÖ **S√©curit√©** avec cl√©s API c√¥t√© serveur uniquement

## üèóÔ∏è Architecture Globale

```mermaid
graph TD
    subgraph CLIENT["CLIENT (Browser)"]
        UI[Interface Utilisateur]
        DS[Domain Services]
        AC[API Clients]
    end

    subgraph SERVER["SERVER (Next.js)"]
        TR[/api/calls/transcribe]
        DR[/api/calls/diarize]
        OAPI[OpenAI SDK]
        AAPI[AssemblyAI SDK]
    end

    subgraph EXTERNAL["EXTERNAL SERVICES"]
        OpenAI[OpenAI API]
        AssemblyAI[AssemblyAI API]
    end

    UI --> DS
    DS --> AC
    AC --> TR
    AC --> DR
    TR --> OAPI
    DR --> AAPI
    OAPI --> OpenAI
    AAPI --> AssemblyAI
````

## üîÑ Flow Chart D√©taill√©

### Flux Complet de Transcription

```mermaid
flowchart TD
    Start([D√©marrage]) --> GetCall[R√©cup√©ration Call]
    GetCall --> CheckAudio{Audio disponible?}
    CheckAudio -->|Non| Error1[Erreur: Pas d'audio]
    CheckAudio -->|Oui| GenerateURL[G√©n√©ration URL sign√©e]

    GenerateURL --> ChooseMode{Mode de transcription?}

    ChooseMode -->|transcription-only| TranscriptionFlow[Flux Transcription]
    ChooseMode -->|diarization-only| DiarizationFlow[Flux Diarisation]
    ChooseMode -->|complete| CompleteFlow[Flux Complet]

    TranscriptionFlow --> CallWhisper[Appel OpenAI Whisper]
    CallWhisper --> ParseSegments[Extraction Segments + Mots]
    ParseSegments --> Normalize[Normalisation ASR]
    Normalize --> SaveTranscript[Sauvegarde]
    SaveTranscript --> EndTranscript([Fin Transcription])

    DiarizationFlow --> CheckExisting{Transcription existe?}
    CheckExisting -->|Non| Error2[Erreur: Pas de transcription]
    CheckExisting -->|Oui| CallAssembly[Appel AssemblyAI]
    CallAssembly --> ExtractSpeakers[Extraction Speakers]
    ExtractSpeakers --> AlignWords[Alignement Mots/Speakers]
    AlignWords --> SaveDiar[Sauvegarde]
    SaveDiar --> EndDiar([Fin Diarisation])

    CompleteFlow --> CallWhisperComp[Appel OpenAI]
    CallWhisperComp --> CallAssemblyComp[Appel AssemblyAI]
    CallAssemblyComp --> AlignComplete[Alignement Complet]
    AlignComplete --> ValidateAll[Validation]
    ValidateAll --> SaveComplete[Sauvegarde Compl√®te]
    SaveComplete --> EndComplete([Fin Compl√®te])

    Error1 --> EndError([√âchec])
    Error2 --> EndError

    CallWhisper -->|Erreur| Retry1{Retry?}
    CallAssembly -->|Erreur| Retry2{Retry?}
    Retry1 -->|Oui| CallWhisper
    Retry1 -->|Non| EndError
    Retry2 -->|Oui| CallAssembly
    Retry2 -->|Non| EndError
```

### Flux d'Alignement ASR ‚Üî Diarisation

```mermaid
graph LR
    subgraph ASR["ASR Results"]
        W1["Word 1: Bonjour (0.5-1.2s)"]
        W2["Word 2: je (1.2-1.8s)"]
        W3["Word 3: suis (1.8-2.5s)"]
        W4["Word 4: Marie (2.5-3.2s)"]
        W5["Word 5: oui (3.8-4.5s)"]
    end

    subgraph DIAR["Diarization Results"]
        S1["Speaker A: 0.0-3.0s (conf: 0.92)"]
        S2["Speaker B: 3.5-5.0s (conf: 0.89)"]
    end

    subgraph RESULT["Final Result"]
        R1["Word 1: Speaker A"]
        R2["Word 2: Speaker A"]
        R3["Word 3: Speaker A"]
        R4["Word 4: Speaker A"]
        R5["Word 5: Speaker B"]
    end

    W1 --> R1
    W2 --> R2
    W3 --> R3
    W4 --> R4
    W5 --> R5

    S1 -.-> R1
    S1 -.-> R2
    S1 -.-> R3
    S1 -.-> R4
    S2 -.-> R5
```

## üß© Composants Principaux

### 1. üåê API Routes (Infrastructure)

#### `/api/calls/transcribe`

```typescript
// Responsabilit√©s :
// ‚úÖ Appel direct OpenAI Whisper API
// ‚úÖ R√©cup√©ration segments + mots temporels
// ‚úÖ Gestion erreurs OpenAI (auth, quota, timeout)
// ‚úÖ Health checks

POST /api/calls/transcribe
{
  "fileUrl": "https://storage.com/audio.wav",
  "options": {
    "model": "whisper-1",
    "language": "fr",
    "temperature": 0,
    "prompt": "Centre de contact, service client"
  }
}

Response:
{
  "success": true,
  "result": {
    "task": "transcribe",
    "language": "fr",
    "duration": 125.4,
    "text": "Bonjour je suis Marie...",
    "segments": [...], // üéØ Segments temporels structur√©s
    "words": [...]     // üéØ Mots avec timestamps
  },
  "metrics": {
    "processingTimeMs": 8420,
    "estimatedCost": 0.0075
  }
}
```

#### `/api/calls/diarize`

```typescript
// Responsabilit√©s :
// ‚úÖ Appel direct AssemblyAI API
// ‚úÖ Extraction segments speakers
// ‚úÖ Gestion erreurs AssemblyAI
// ‚úÖ Health checks

POST /api/calls/diarize
{
  "fileUrl": "https://storage.com/audio.wav",
  "options": {
    "languageCode": "fr",
    "timeoutMs": 600000
  }
}

Response:
{
  "success": true,
  "result": [
    {
      "start": 0.0,
      "end": 12.5,
      "speaker": "SPEAKER_00",
      "confidence": 0.92
    },
    {
      "start": 12.8,
      "end": 25.3,
      "speaker": "SPEAKER_01",
      "confidence": 0.89
    }
  ]
}
```

### 2. üéØ Domain Services (Logique M√©tier)

#### `TranscriptionASRService`

```typescript
// Responsabilit√©s :
// ‚úÖ Normalisation formats OpenAI ‚Üí standard
// ‚úÖ Segmentation intelligente pour diarisation
// ‚úÖ Assignation tours de parole (mots ‚Üî speakers)
// ‚úÖ Validation et m√©triques qualit√©
// ‚úÖ Algorithmes d'alignement avanc√©s

class TranscriptionASRService {
  // Entr√©e : R√©ponse brute OpenAI
  // Sortie : Format standardis√© avec segments
  normalize(rawOpenAI: WhisperResponse): TranscriptionJson;

  // Assignation basique avec tol√©rance temporelle
  assignTurns(words: Word[], speakers: DiarizationSegment[]): Word[];

  // Assignation avanc√©e avec gestion conflits
  assignTurnsOverlap(words, speakers, options): Word[];

  // Validation compl√®te avec m√©triques
  validateAll(words: Word[]): ValidationResult;
}
```

#### `TranscriptionIntegrationService`

```typescript
// Responsabilit√©s :
// ‚úÖ Orchestration compl√®te du workflow
// ‚úÖ Gestion des modes (transcription/diarisation/complet)
// ‚úÖ Appels coordonn√©s aux API routes
// ‚úÖ Traitement en lot avec gestion concurrence
// ‚úÖ M√©triques et monitoring

class TranscriptionIntegrationService {
  // Workflow complet
  transcribeComplete(callId: string): Promise<TranscriptionJobResult>;

  // Workflows partiels
  transcribeOnly(callId: string): Promise<TranscriptionJobResult>;
  diarizeExisting(callId: string): Promise<TranscriptionJobResult>;

  // Traitement en lot
  transcribeBatch(
    callIds: string[],
    options
  ): Promise<BatchTranscriptionResult>;
}
```

#### `DiarizationService`

```typescript
// Responsabilit√©s :
// ‚úÖ Logique d'alignement mots ‚Üî speakers
// ‚úÖ Preprocessing segments (fusion, validation)
// ‚úÖ R√©solution conflits et am√©lioration coh√©rence
// ‚úÖ Analyse qualit√© diarisation
// ‚úÖ Outils debugging et visualisation

class DiarizationService {
  // M√©thode principale d'assignation
  assignTurnsToWords(words, diarizationSegments, options): Word[];

  // Analyse qualit√© avec recommandations
  analyzeDiarizationQuality(words, segments): QualityAnalysis;

  // Debug et visualisation
  generateTimelineVisualization(words, segments): string[];
}
```

### 3. üíª API Clients (Transport HTTP)

#### `TranscriptionApiClient`

```typescript
// Responsabilit√©s :
// ‚úÖ Wrapper HTTP vers /api/calls/transcribe
// ‚úÖ Gestion timeouts et retry c√¥t√© client
// ‚úÖ Parsing r√©ponses et gestion erreurs r√©seau
// ‚úÖ Health checks c√¥t√© client

class TranscriptionApiClient {
  async transcribeAudio(fileUrl: string, options): Promise<WhisperResponse>;
  async healthCheck(): Promise<HealthStatus>;
}
```

## üìä Flux de Donn√©es

### Formats d'√âchange

#### 1. üìù Word (Unit√© de Base)

```typescript
interface Word {
  text: string; // "Bonjour"
  startTime: number; // 0.5 (secondes)
  endTime: number; // 1.2 (secondes)
  turn?: string; // "SPEAKER_00" (apr√®s diarisation)
  type?: string; // "word" | "punctuation" | "hesitation"
}
```

#### 2. üìã AsrSegment (Segment ASR)

```typescript
interface AsrSegment {
  id: string; // "seg_0001"
  start: number; // 0.5 (secondes)
  end: number; // 12.8 (secondes)
  text: string; // "Bonjour je suis Marie du service client"
  words: Word[]; // Mots contenus dans le segment
}
```

#### 3. üé≠ DiarizationSegment (Segment Speaker)

```typescript
interface DiarizationSegment {
  start: number; // 0.0 (secondes)
  end: number; // 12.5 (secondes)
  speaker: string; // "SPEAKER_00"
  confidence?: number; // 0.92 (0-1)
}
```

#### 4. üìÑ TranscriptionJson (Format Final)

```typescript
interface TranscriptionJson {
  words: Word[]; // ‚úÖ Mots avec tours assign√©s
  segments?: AsrSegment[]; // ‚úÖ Segments ASR (nouveaut√©)
  meta?: {
    version: string; // "1.1"
    createdAt: string; // ISO timestamp
    source: "asr:auto";
    language: string; // "fr-FR"
    durationSec: number; // 125.4
    speakerCount?: number; // 2 (apr√®s diarisation)
    transcriptionProvider?: string; // "openai-whisper"
    diarizationProvider?: string; // "assemblyai"
  };
}
```

## üöÄ Exemples d'Usage

### Transcription Compl√®te

```typescript
// 1. Initialisation du service
const integrationService = createTranscriptionIntegrationService(
  callRepository,
  storageRepository
);

// 2. Transcription compl√®te (ASR + Diarisation + Alignement)
const result = await integrationService.transcribeComplete("call-123");

if (result.success) {
  console.log(`‚úÖ Transcription r√©ussie:`);
  console.log(`- Dur√©e: ${result.metrics.audioDuration}s`);
  console.log(`- Mots: ${result.metrics.wordCount}`);
  console.log(`- Speakers: ${result.metrics.speakerCount}`);
  console.log(`- Co√ªt: $${result.metrics.totalCost.toFixed(4)}`);

  // Acc√®s aux mots avec tours
  result.transcription?.words.forEach((word) => {
    console.log(`${word.startTime}s: [${word.turn}] "${word.text}"`);
  });
} else {
  console.error(`‚ùå √âchec: ${result.error}`);
}
```

### Traitement en Lot

```typescript
const batchResult = await integrationService.transcribeBatch(
  ["call-123", "call-456", "call-789"],
  {
    mode: "complete",
    maxConcurrent: 3,
    pauseBetweenBatches: 2000,
    onProgress: (completed, total, current) => {
      console.log(`üìä Progression: ${completed}/${total}`);
      if (current?.success) {
        console.log(`‚úÖ ${current.callId}: ${current.metrics.wordCount} mots`);
      }
    },
  }
);

console.log(`üéâ Lot termin√©:`);
console.log(`- Succ√®s: ${batchResult.successfulJobs}/${batchResult.totalJobs}`);
console.log(`- Co√ªt total: $${batchResult.totalCost.toFixed(4)}`);
console.log(
  `- Temps moyen: ${(batchResult.averageProcessingTime / 1000).toFixed(1)}s`
);
```

### Analyse de Qualit√©

```typescript
const diarizationService = new DiarizationService();

// Analyse de la qualit√© de diarisation
const quality = diarizationService.analyzeDiarizationQuality(
  transcription.words,
  diarizationSegments
);

console.log(`üìä Qualit√©: ${quality.quality}`);
if (quality.issues.length > 0) {
  console.log(`‚ö†Ô∏è Probl√®mes d√©tect√©s:`);
  quality.issues.forEach((issue) => console.log(`  - ${issue}`));

  console.log(`üí° Recommandations:`);
  quality.recommendations.forEach((rec) => console.log(`  - ${rec}`));
}

// Visualisation timeline
const timeline = diarizationService.generateTimelineVisualization(
  transcription.words,
  diarizationSegments
);
timeline.forEach((line) => console.log(line));
```

## üîÑ Migration depuis l'Ancienne Architecture

### Avant (Probl√©matique)

```typescript
// ‚ùå Ancien syst√®me - providers dans routes API
export async function POST(request: NextRequest) {
  // Provider interm√©diaire inutile
  const provider = new OpenAIWhisperProvider(apiKey);
  const result = await provider.transcribeAudio(fileUrl);
  // Pas de segments structur√©s
  return { text: result.text }; // ‚Üê Un seul bloc de texte !
}
```

### Apr√®s (Clean)

```typescript
// ‚úÖ Nouveau syst√®me - SDK direct + segments
export async function POST(request: NextRequest) {
  // SDK direct OpenAI
  const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

  const result = await openai.audio.transcriptions.create({
    file: audioFile,
    response_format: "verbose_json",
    timestamp_granularities: ["word", "segment"], // ‚Üê Segments !
  });

  return {
    success: true,
    result: {
      text: result.text,
      segments: result.segments, // ‚Üê Segments temporels
      words: result.words, // ‚Üê Mots avec timestamps
    },
  };
}
```

### Checklist de Migration

- [ ] ‚úÖ Supprimer `OpenAIWhisperProvider` et `AssemblyAIDiarizationProvider`
- [ ] ‚úÖ Remplacer par appels directs SDK dans routes API
- [ ] ‚úÖ Mettre √† jour `TranscriptionASRService` pour g√©rer segments
- [ ] ‚úÖ Adapter `TranscriptionIntegrationService` pour API routes
- [ ] ‚úÖ Simplifier API Clients en wrappers l√©gers
- [ ] ‚úÖ Tester l'alignement ASR ‚Üî Diarisation avec segments
- [ ] ‚úÖ Valider les m√©triques et co√ªts
- [ ] ‚úÖ Monitoring et alertes

## üìà Monitoring et M√©triques

### M√©triques Collect√©es

```typescript
interface TranscriptionMetrics {
  // Performance
  processingTime: number; // Temps total (ms)
  audioDuration: number; // Dur√©e audio (s)

  // Qualit√©
  wordCount: number; // Nombre de mots
  speakerCount: number; // Nombre de locuteurs
  segmentCount: number; // Nombre de segments

  // Co√ªts
  whisperCost: number; // Co√ªt OpenAI ($)
  assemblyAICost: number; // Co√ªt AssemblyAI ($)
  totalCost: number; // Co√ªt total ($)

  // Qualit√© Diarisation
  turnCoverage: number; // % mots avec speaker (0-100)
  averageConfidence: number; // Confidence moyenne (0-1)
}
```

### Health Checks

```typescript
// V√©rification sant√© des services
const health = await callsApiClient.getServicesHealth()

// R√©sultat
{
  transcription: {
    status: "healthy",
    responseTime: 245,
    openaiStatus: "available"
  },
  diarization: {
    status: "healthy",
    responseTime: 189,
    assemblyaiStatus: "available"
  },
  overall: "healthy", // healthy | degraded | unhealthy
  lastChecked: "2024-01-15T10:30:00Z"
}
```

## üéØ Roadmap & Am√©liorations

### Phase 1 - ‚úÖ Termin√©e

- [x] Architecture DDD avec s√©paration clean
- [x] API Routes directes sans providers
- [x] Gestion segments ASR pour synchronisation
- [x] Algorithmes alignement avanc√©s
- [x] Validation et m√©triques qualit√©

### Phase 2 - üöß En cours

- [ ] M√©triques persistantes en base de donn√©es
- [ ] Dashboard monitoring temps r√©el
- [ ] API de batch processing asynchrone
- [ ] Cache intelligent multi-niveaux
- [ ] Webhooks pour notifications

### Phase 3 - üìã Planifi√©e

- [ ] Support Azure OpenAI et autres providers
- [ ] Mod√®les Whisper locaux (auto-h√©berg√©s)
- [ ] ML Pipeline pour am√©lioration continue
- [ ] API GraphQL pour requ√™tes complexes
- [ ] Int√©gration Prometheus/Grafana

---

## ü§ù Contributing

Cette architecture respecte les principes **Domain-Driven Design** avec une s√©paration claire des responsabilit√©s. Chaque modification doit pr√©server :

- **Domain purity** : Logique m√©tier ind√©pendante de l'infrastructure
- **API security** : Cl√©s API prot√©g√©es c√¥t√© serveur uniquement
- **Performance** : Segments structur√©s pour synchronisation optimale
- **Observability** : M√©triques et logs d√©taill√©s √† chaque √©tape

---

**Statut** : ‚úÖ Production Ready

**Version** : 2.0

**Derni√®re mise √† jour** : Janvier 2025

<style>#mermaid-1758696502972{font-family:sans-serif;font-size:16px;fill:#333;}#mermaid-1758696502972 .error-icon{fill:#552222;}#mermaid-1758696502972 .error-text{fill:#552222;stroke:#552222;}#mermaid-1758696502972 .edge-thickness-normal{stroke-width:2px;}#mermaid-1758696502972 .edge-thickness-thick{stroke-width:3.5px;}#mermaid-1758696502972 .edge-pattern-solid{stroke-dasharray:0;}#mermaid-1758696502972 .edge-pattern-dashed{stroke-dasharray:3;}#mermaid-1758696502972 .edge-pattern-dotted{stroke-dasharray:2;}#mermaid-1758696502972 .marker{fill:#333333;}#mermaid-1758696502972 .marker.cross{stroke:#333333;}#mermaid-1758696502972 svg{font-family:sans-serif;font-size:16px;}#mermaid-1758696502972 .label{font-family:sans-serif;color:#333;}#mermaid-1758696502972 .label text{fill:#333;}#mermaid-1758696502972 .node rect,#mermaid-1758696502972 .node circle,#mermaid-1758696502972 .node ellipse,#mermaid-1758696502972 .node polygon,#mermaid-1758696502972 .node path{fill:#ECECFF;stroke:#9370DB;stroke-width:1px;}#mermaid-1758696502972 .node .label{text-align:center;}#mermaid-1758696502972 .node.clickable{cursor:pointer;}#mermaid-1758696502972 .arrowheadPath{fill:#333333;}#mermaid-1758696502972 .edgePath .path{stroke:#333333;stroke-width:1.5px;}#mermaid-1758696502972 .flowchart-link{stroke:#333333;fill:none;}#mermaid-1758696502972 .edgeLabel{background-color:#e8e8e8;text-align:center;}#mermaid-1758696502972 .edgeLabel rect{opacity:0.5;background-color:#e8e8e8;fill:#e8e8e8;}#mermaid-1758696502972 .cluster rect{fill:#ffffde;stroke:#aaaa33;stroke-width:1px;}#mermaid-1758696502972 .cluster text{fill:#333;}#mermaid-1758696502972 div.mermaidTooltip{position:absolute;text-align:center;max-width:200px;padding:2px;font-family:sans-serif;font-size:12px;background:hsl(80,100%,96.2745098039%);border:1px solid #aaaa33;border-radius:2px;pointer-events:none;z-index:100;}#mermaid-1758696502972:root{--mermaid-font-family:sans-serif;}#mermaid-1758696502972:root{--mermaid-alt-font-family:sans-serif;}#mermaid-1758696502972 flowchart{fill:apa;}</style>
