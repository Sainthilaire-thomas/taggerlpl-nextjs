# üéôÔ∏è Roadmap Transcription & Diarisation Automatique - TaggerLPL

## √âtat Actualis√© - Septembre 2025

---

## üìã √âtat Actuel de l'Impl√©mentation

### ‚úÖ **COMPLET** - Ce qui est enti√®rement fonctionnel

#### 1. **Architecture DDD Compl√®te et Op√©rationnelle**

- ‚úÖ **Entit√©s Domain** : `Call`, `CallExtended`, `AudioFile`, `Transcription`, `TranscriptionWord`
  - `CallExtended` avec cycle de vie workflow int√©gr√©
  - Support complet des flags `preparedfortranscript`, `is_tagging_call`, `isTagged`
  - Factory methods pour cr√©ation depuis base de donn√©es
- ‚úÖ **Services M√©tier Complets** :
  - `CallService`, `CallLifecycleService`, `ValidationService`
  - `TranscriptionTransformationService` (JSON ‚Üí table word)
  - `CallFilteringService` (filtrage avanc√©)
  - `DuplicateService`, `StorageService`
- ‚úÖ **Repositories Supabase** :
  - `SupabaseCallRepository` avec m√©thodes workflow enrichies
  - `SupabaseStorageRepository` avec gestion URLs sign√©es
  - `SupabaseRelationsRepository` pour statistiques next_turn
- ‚úÖ **ServiceFactory** :
  - Factory pattern avec injection de d√©pendances
  - Service compos√© `callPreparationService`
  - Configuration et health checks

#### 2. **Base de Donn√©es & Stockage Op√©rationnels**

```sql
-- Tables existantes et optimis√©es
‚úÖ call (callid, filename, filepath, transcription, preparedfortranscript, is_tagging_call)
‚úÖ transcript (callid, transcriptid)
‚úÖ word (transcriptid, word, startTime, endTime, speaker, turn)
‚úÖ lpltag (label, family, originespeaker, color, icon)
‚úÖ turntagged (call_id, start_time, end_time, tag, verbatim, speaker, next_turn_tag)

-- Vues optimis√©es cr√©√©es
‚úÖ call_with_tagging_status (jointure call + turntagged pour performances)
‚úÖ call_relations_stats (statistiques next_turn pr√©-calcul√©es)
```

#### 3. **UI & Workflow Avanc√©s**

- ‚úÖ **CallManagementPage** : Interface compl√®te avec onglets multiples
- ‚úÖ **TranscriptLPL** : Lecteur synchronis√© avec tagging interactif
- ‚úÖ **TagManager** : Gestion avanc√©e des tags avec statistiques
- ‚úÖ **Analysis** : Centre d'analyse conversationnelle
- ‚úÖ **Hooks Optimis√©s** : `useUnifiedCallManagement`, `useCallTranscriptionActions`
- ‚úÖ **Cache Intelligent** : Syst√®me multi-niveaux avec invalidation
- ‚úÖ **Actions en Lot** : S√©lection multiple, traitement par batch

#### 4. **Services de Transformation Fonctionnels**

- ‚úÖ **TranscriptionTransformationService** :
  - Validation compl√®te de la structure JSON
  - Transformation JSON ‚Üí entit√©s `TranscriptionWord`
  - Insertion par batch dans table `word` via `transcript`
  - Gestion des erreurs et rollback
  - Statistiques de transformation
- ‚úÖ **CallLifecycleService** :
  - Gestion du cycle de vie complet des appels
  - Actions : prepare, select, unselect, tag
  - Validation des r√®gles m√©tier
  - Statistiques par √©tape du workflow

---

## üöß **EN COURS** - Ce qui est partiellement impl√©ment√©

### Phase 1 : Infrastructure ASR & Diarisation (70% compl√©t√©)

#### A. Provider OpenAI Whisper (‚úÖ Structure, ‚ö†Ô∏è Int√©gration)

```typescript
// ‚úÖ IMPL√âMENT√â : src/components/calls/infrastructure/asr/OpenAIWhisperProvider.ts
export class OpenAIWhisperProvider {
  constructor(private apiKey: string, private baseUrl: string) {}

  async transcribeAudio(
    fileUrl: string,
    options: OpenAIWhisperOptions = {}
  ): Promise<any> {
    // ‚úÖ T√©l√©chargement audio depuis URL sign√©e
    // ‚úÖ Appel API OpenAI /v1/audio/transcriptions
    // ‚úÖ Format "verbose_json" pour timestamps
    // ‚úÖ Gestion d'erreurs robuste
  }
}

// ‚ö†Ô∏è MANQUE : Configuration environnement et tests
// - Variables ENV : OPENAI_API_KEY, OPENAI_BASE_URL
// - Tests d'int√©gration avec diff√©rents formats audio
// - Gestion des quotas et rate limiting
```

#### B. Provider Diarisation Externe (‚úÖ Interface, ‚ö†Ô∏è Impl√©mentation)

```typescript
// ‚úÖ IMPL√âMENT√â : src/components/calls/infrastructure/diarization/ExternalDiarizationProvider.ts
export interface IDiarizationProvider {
  inferSpeakers(
    fileUrl: string,
    options?: ExternalDiarizationOptions
  ): Promise<DiarizationSegment[]>;
}

export class ExternalDiarizationProvider implements IDiarizationProvider {
  // ‚ö†Ô∏è ACTUEL : Mock implementation avec segments simul√©s
  // üîÑ TODO : Int√©gration r√©elle avec AssemblyAI/Pyannote
}

// Options √† √©valuer :
// 1. AssemblyAI (API simple, 0.07$/min) - RECOMMAND√â
// 2. Pyannote.audio (gratuit mais complexe √† d√©ployer)
// 3. Deepgram (0.15$/min, tr√®s pr√©cis)
```

#### C. Service ASR Int√©gr√© (‚úÖ Base, ‚ö†Ô∏è Finalisation)

```typescript
// ‚úÖ IMPL√âMENT√â : src/components/calls/domain/services/TranscriptionASRService.ts
export class TranscriptionASRService {
  // ‚úÖ normalize() : OpenAI JSON ‚Üí format TaggerLPL
  // ‚úÖ assignTurns() : Application diarisation ‚Üí mots
  // ‚úÖ validateAll() : Validation coh√©rence
  // ‚úÖ insertTag(), splitAt(), mergeRange() : √âdition
  // ‚ö†Ô∏è EN COURS : Optimisation algorithmes alignement temporel
  // ‚ö†Ô∏è TODO : Gestion des cas limites (chevauchements, silences)
}
```

### Phase 2 : Workflow ASR Complet (‚úÖ Architecture, ‚ö†Ô∏è Tests)

```typescript
// ‚úÖ IMPL√âMENT√â : src/components/calls/domain/workflows/TranscriptionASRWorkflow.ts
export class TranscriptionASRWorkflow {
  // ‚úÖ transcribe() : Audio ‚Üí JSON normalis√© ‚Üí sauvegarde
  // ‚úÖ diarize() : Audio ‚Üí segments ‚Üí assignation speakers
  // ‚úÖ validateAndSave() : Validation finale + persistence
  // ‚ö†Ô∏è EN COURS : Tests end-to-end avec vrais providers
  // ‚ö†Ô∏è TODO : Gestion des erreurs r√©seau et timeouts
}
```

---

## ‚ùå **√Ä IMPL√âMENTER** - Ce qui reste √† faire

### Sprint 1 : Finalisation Infrastructure (1-2 semaines)

#### 1. **Configuration & D√©ploiement Provider OpenAI**

- [ ] Variables d'environnement (`OPENAI_API_KEY`)
- [ ] Tests avec diff√©rents formats audio (mp3, wav, m4a)
- [ ] Gestion quotas et rate limiting
- [ ] Monitoring co√ªts (~0.006$/minute)

#### 2. **Choix & Int√©gration Provider Diarisation**

**Option recommand√©e : AssemblyAI**

```typescript
// √Ä cr√©er : AssemblyAIDiarizationProvider.ts
export class AssemblyAIDiarizationProvider implements IDiarizationProvider {
  async inferSpeakers(audioUrl: string): Promise<DiarizationSegment[]> {
    // 1. Upload vers AssemblyAI
    // 2. Lancer transcription + diarisation
    // 3. Polling r√©sultats
    // 4. Extraction segments speakers
  }
}
```

- [ ] Int√©gration API AssemblyAI
- [ ] Configuration variables ENV
- [ ] Tests qualit√© diarisation
- [ ] Calcul co√ªts (~0.07$/minute)

### Sprint 2 : Interface Utilisateur Automatique (1-2 semaines)

#### 1. **Int√©gration UI CallManagementPage**

```typescript
// √Ä modifier : src/components/calls/ui/hooks/actions/useCallTranscriptionActions.ts
export function useCallTranscriptionActions({ reload }: Props) {
  const { asrWorkflow } = createServices();

  const autoTranscribe = useCallback(
    async (calls: Call[]) => {
      for (const call of calls) {
        // ‚úÖ Service disponible, ‚ùå int√©gration UI manquante
        const result = await asrWorkflow.transcribe(call.id);
        // TODO: Feedback utilisateur, gestion erreurs
      }
      await reload();
    },
    [asrWorkflow, reload]
  );

  const separateSpeakers = useCallback(
    async (calls: Call[]) => {
      for (const call of calls) {
        // ‚ùå √Ä impl√©menter
        const result = await asrWorkflow.diarize(call.id);
      }
      await reload();
    },
    [asrWorkflow, reload]
  );

  // ‚ùå validateTranscriptions d√©j√† impl√©ment√© c√¥t√© service
}
```

#### 2. **Composants de Progression**

```typescript
// √Ä cr√©er : src/components/calls/ui/components/TranscriptionProgress.tsx
export const TranscriptionProgress: React.FC<{
  callId: string;
  stage: "transcribing" | "diarizing" | "validating" | "complete";
  progress: number;
}> = ({ callId, stage, progress }) => {
  // ‚ùå Interface de progression temps r√©el
  // ‚ùå Estimation temps restant
  // ‚ùå Gestion annulation/retry
};
```

#### 3. **Boutons d'Action CallManagementPage**

```typescript
// √Ä modifier : src/components/calls/ui/sections/CMActionsBar.tsx
case "transcription":
  return (
    <Box display="flex" gap={1} flexWrap="wrap">
      {/* ‚ùå Int√©gration r√©elle avec services */}
      <Button onClick={() => transcription.autoTranscribe(selectedCalls)}>
        üéôÔ∏è Transcrire Auto ({selectedCount})
      </Button>

      <Button onClick={() => transcription.separateSpeakers(selectedCalls)}>
        üë• S√©parer Locuteurs
      </Button>

      {/* ‚úÖ Validation d√©j√† impl√©ment√©e */}
      <Button onClick={() => transcription.validateTranscriptions(selectedCalls)}>
        ‚úÖ Valider & Corriger
      </Button>
    </Box>
  );
```

### Sprint 3 : Optimisations & Production (1 semaine)

#### 1. **Performance & Parall√©lisation**

- [ ] Traitement par lots optimis√© (5 appels max en parall√®le)
- [ ] Queue system pour gros volumes
- [ ] Cache r√©sultats ASR/Diarisation
- [ ] Compression JSON transcriptions

#### 2. **Monitoring & Observabilit√©**

- [ ] Logs structur√©s pour chaque √©tape
- [ ] M√©triques performance (temps, co√ªts, pr√©cision)
- [ ] Alertes erreurs providers externes
- [ ] Dashboard monitoring temps r√©el

#### 3. **Gestion d'Erreurs Robuste**

- [ ] Retry automatique avec backoff exponential
- [ ] Fallback sur √©chec provider (OpenAI ‚Üí local Whisper?)
- [ ] Notification utilisateur erreurs persistantes
- [ ] Recovery automatique apr√®s panne

---

## üéØ M√©triques de Performance Cibles

### Fonctionnel

- ‚úÖ **Vitesse transformation** : < 500ms (JSON ‚Üí table word)
- ‚ö†Ô∏è **Vitesse transcription** : < 0.3x temps r√©el (objectif, non test√©)
- ‚ùå **Pr√©cision Whisper** : > 95% WER (√† mesurer)
- ‚ùå **Pr√©cision diarisation** : > 85% SER (√† mesurer)

### √âconomique

- ‚ùå **Co√ªt par appel** : < 0.10‚Ç¨ (transcription + diarisation)
- ‚ùå **Co√ªt OpenAI** : ~0.006$/minute (√† valider)
- ‚ùå **Co√ªt diarisation** : ~0.07$/minute AssemblyAI

### Technique

- ‚úÖ **Disponibilit√© services** : 99% (Supabase + infrastructure)
- ‚ùå **Uptime providers** : 99% (OpenAI + AssemblyAI)
- ‚úÖ **Temps r√©ponse API** : < 200ms (services internes)

---

## üìä Comparatif Providers de Diarisation

| Provider       | Co√ªt       | Qualit√©    | Facilit√©   | Recommandation   | √âtat           |
| -------------- | ---------- | ---------- | ---------- | ---------------- | -------------- |
| AssemblyAI     | ~0.07$/min | ‚≠ê‚≠ê‚≠ê‚≠ê   | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚úÖ**Recommand√©** | ‚ùå √Ä int√©grer  |
| Pyannote.audio | Gratuit    | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê       | Budget serr√©     | ‚ùå Non √©valu√©  |
| Deepgram       | ~0.15$/min | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê   | Si budget √©lev√©  | ‚ùå Non √©valu√©  |
| Mock√©e         | Gratuit    | ‚≠ê         | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | Dev uniquement   | ‚úÖ Impl√©ment√©e |

---

## üöÄ Plan d'Impl√©mentation Recommand√©

### Phase 1 : Providers Externes (2-3 semaines)

**Priorit√© : HAUTE**

1. **Semaine 1** : Configuration OpenAI Whisper
   - Variables d'environnement production
   - Tests formats audio (mp3, wav, m4a, aac)
   - Validation qualit√© transcription fran√ßais
   - Monitoring co√ªts et quotas
2. **Semaine 2** : Int√©gration AssemblyAI
   - Configuration compte + API key
   - Impl√©mentation `AssemblyAIDiarizationProvider`
   - Tests qualit√© diarisation 2-5 speakers
   - Validation alignement temporal avec Whisper
3. **Semaine 3** : Tests End-to-End
   - Workflow complet Audio ‚Üí Transcription ‚Üí Diarisation
   - Validation avec corpus test (10-20 appels)
   - Optimisation alignement temporel
   - Correction des cas limites

### Phase 2 : Interface Utilisateur (1-2 semaines)

**Priorit√© : MOYENNE**

1. **Int√©gration boutons UI** (3-4 jours)
   - Modification `useCallTranscriptionActions`
   - Ajout boutons `CMActionsBar`
   - Int√©gration workflow ASR r√©els
   - Tests utilisateur basiques
2. **Composants de progression** (3-4 jours)
   - Interface `TranscriptionProgress`
   - WebSocket temps r√©el (optionnel)
   - Notifications toast success/error
   - Gestion annulation utilisateur

### Phase 3 : Production & Monitoring (1 semaine)

**Priorit√© : FAIBLE**

1. **Optimisations performance** (2-3 jours)
   - Parall√©lisation contr√¥l√©e
   - Cache intelligent r√©sultats
   - Compression stockage
2. **Monitoring production** (2-3 jours)
   - Logs structur√©s JSON
   - M√©triques Prometheus/DataDog
   - Alertes PagerDuty/Slack
   - Dashboard Grafana

---

## ‚ö†Ô∏è Points d'Attention Critiques

### 1. **Gestion des Co√ªts**

```typescript
// Configuration recommand√©e OpenAI
const WHISPER_CONFIG = {
  model: "whisper-1",
  response_format: "verbose_json",
  language: "fr", // Optimisation fran√ßais
  temperature: 0.0, // D√©terministe
};

// Estimation: 1000 appels x 5min = ~30$ OpenAI + ~350$ AssemblyAI = 380$/mois
// CRITIQUE : Pr√©voir budget et monitoring co√ªts temps r√©el
```

### 2. **Alignement Temporel**

```typescript
// ATTENTION : Synchronisation critique entre ASR et diarisation
const alignmentTolerance = 0.1; // 100ms de tol√©rance

// Probl√®me fr√©quent : d√©calage entre timestamps Whisper et AssemblyAI
// Solution impl√©ment√©e dans TranscriptionASRService.assignTurns()
```

### 3. **Formats Audio Support√©s**

```typescript
// Whisper supporte : mp3, mp4, wav, flac, m4a, webm
// Votre BDD contient : wav principalement
// ‚ö†Ô∏è Conversion automatique n√©cessaire si autres formats
```

### 4. **Rate Limiting & Quotas**

- **OpenAI** : 500 requ√™tes/minute, 200,000 tokens/minute
- **AssemblyAI** : Quotas selon abonnement
- **Solution** : Queue avec backoff, retry automatique

---

## üîó Int√©gration avec l'Existant

### Architecture DDD Conserv√©e ‚úÖ

1. **Domain Services** ‚Üí `TranscriptionASRService` s'int√®gre naturellement
2. **Infrastructure** ‚Üí Nouveaux providers avec interfaces claires
3. **UI Hooks** ‚Üí Extension de `useCallTranscriptionActions` existant
4. **Database** ‚Üí Aucune modification structurelle requise
5. **CallLifecycleService** ‚Üí Nouveau statut "auto-transcribed"

### Workflow Utilisateur Enrichi ‚úÖ

```
Import Audio ‚Üí [NOUVEAU] Auto-Transcription ‚Üí [NOUVEAU] Auto-Diarisation
             ‚Üí [EXISTANT] Validation ‚Üí [EXISTANT] Pr√©paration
             ‚Üí [EXISTANT] Tagging ‚Üí [EXISTANT] Analyse
```

### Points d'Extension Futurs üöÄ

1. **IA Generative** : R√©sum√© automatique des appels
2. **Analyse Sentiment** : Classification √©motionnelle automatique
3. **D√©tection Topics** : Cat√©gorisation automatique par sujet
4. **Quality Assurance** : Scoring automatique qualit√© interaction
5. **Real-time** : Transcription live pendant l'appel

---

## üìà ROI Estim√©

### Gains Quantifi√©s

- **Temps transcription** : 30min manuel ‚Üí 2min automatique = **93% r√©duction**
- **Co√ªt transcripteur** : 25‚Ç¨/h ‚Üí 0.10‚Ç¨/appel automatique = **99% r√©duction**
- **D√©lai traitement** : 24-48h ‚Üí 5min = **99.9% r√©duction**
- **Qualit√© diarisation** : Variable manuelle ‚Üí 85%+ automatique

### Investissement Technique

- **D√©veloppement** : ~3 semaines d√©veloppeur senior
- **Co√ªts op√©rationnels** : ~400‚Ç¨/mois pour 1000 appels
- **Infrastructure** : Marginal (Supabase, Vercel existants)

### Break-even : **2-3 mois** pour corpus > 500 appels/mois

Cette roadmap actualis√©e montre que **70% de l'infrastructure est d√©j√† impl√©ment√©e** et que seule l'int√©gration des providers externes r√©els reste critique pour un syst√®me complet de transcription et diarisation automatique ! üöÄ
