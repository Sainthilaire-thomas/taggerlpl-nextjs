# ğŸ”„ ADDENDUM : RÃ©utilisation des Composants Level 1 pour Level 0

*Ajout au document mission-2025-12-15-level0-llm-contra-annotation.md*

---

## ğŸ¯ Principe : RÃ©utiliser, ne pas recrÃ©er

Tu as raison Thomas - on a dÃ©jÃ  **tous les composants d'affichage** dans Level 1. Au lieu de recrÃ©er, on va :

1. **Adapter les donnÃ©es** : Transformer les rÃ©sultats de contre-annotation en format compatible `TVValidationResultCore`
2. **RÃ©utiliser les composants** : `ResultsPanel`, `AnalysisPairContext`, `QuickTagEditDialog`, etc.
3. **CrÃ©er juste la logique mÃ©tier** : Services OpenAI et Kappa

---

## ğŸ“¦ Composants Level 1 dÃ©jÃ  disponibles

### 1. ResultsPanel (affichage principal)

**Localisation** : `src/features/phase3-analysis/level1-validation/ui/components/AlgorithmLab/ResultsSample/ResultsPanel.tsx`

**Props** :
```typescript
interface ResultsPanelProps {
  results: TVValidationResultCore[];
  initialPageSize?: number;
  targetKind: TargetKind;
  classifierLabel: string;
}
```

**Ce qu'il affiche** :
- Tableau paginÃ© avec tous les rÃ©sultats
- Colonnes : Verbatim, Gold, Predicted, Correct, Confidence, Timestamps, Actions
- Filtrage par rÃ©sultat (tous / corrects / erreurs)
- Clic sur ligne pour voir dÃ©tails

**Usage Level 0** :
```typescript
<ResultsPanel
  results={level0Results}  // RÃ©sultats adaptÃ©s depuis contre-annotation
  initialPageSize={10}
  targetKind="X"  // ou "Y"
  classifierLabel="OpenAI GPT-4 (Annotateur 2)"
/>
```

### 2. AnalysisPairContext (affichage contexte)

**Localisation** : `src/features/shared/ui/components/AnalysisPairContext.tsx`

**Props** :
```typescript
interface AnalysisPairContextProps {
  pairId?: number;  // Fetch auto depuis analysis_pairs
  // OU mode manuel :
  prev3?: string;
  prev2?: string;
  prev1?: string;
  conseiller: string;
  client: string;
  next1?: string;
  next2?: string;
  next3?: string;
}
```

**Ce qu'il affiche** :
- Contexte complet : prev3 â†’ prev2 â†’ prev1 â†’ **X (conseiller)** â†’ **Y (client)** â†’ next1 â†’ next2 â†’ next3
- Toggle pour masquer/afficher le contexte Ã©tendu
- Fond bleu pour conseiller, orange pour client
- **Hook intÃ©grÃ©** : fetch automatique si juste `pairId`

**Usage Level 0** :
```typescript
// Mode autonome (le plus simple)
<AnalysisPairContext pairId={disagreement.pairId} />

// Mode manuel si tu veux contrÃ´ler
<AnalysisPairContext
  prev1={disagreement.prev1_verbatim}
  conseiller={disagreement.conseiller_verbatim}
  client={disagreement.client_verbatim}
  next1={disagreement.next1_verbatim}
/>
```

### 3. QuickTagEditDialog (Ã©dition rapide)

**Localisation** : `src/features/phase3-analysis/level1-validation/ui/components/AlgorithmLab/ResultsSample/components/QuickTagEditDialog.tsx`

**Props** :
```typescript
interface QuickTagEditDialogProps {
  open: boolean;
  onClose: () => void;
  turnId: number;
  pairId: number;
  currentTag: string;
  speaker: 'conseiller' | 'client';
  verbatim: string;
  onSuccess?: () => void;
}
```

**Ce qu'il fait** :
- Dialog modal avec sÃ©lecteur de tags
- Mise Ã  jour de `turntagged.tag` (source de vÃ©ritÃ©)
- Synchronisation automatique avec `analysis_pairs`
- Callback `onSuccess` pour refresh UI

**Usage Level 0** : Parfait pour rÃ©soudre les dÃ©saccords !
```typescript
<QuickTagEditDialog
  open={resolveDialogOpen}
  onClose={() => setResolveDialogOpen(false)}
  turnId={disagreement.conseiller_turn_id}  // ou client_turn_id
  pairId={disagreement.pairId}
  currentTag={disagreement.manualTag}  // Tag actuel
  speaker="conseiller"  // ou "client"
  verbatim={disagreement.conseiller_verbatim}
  onSuccess={handleResolutionSuccess}
/>
```

### 4. ResultsTableBody (tableau dÃ©taillÃ©)

**Localisation** : `src/features/phase3-analysis/level1-validation/ui/components/AlgorithmLab/ResultsSample/components/ResultsTableBody.tsx`

**Ce qu'il affiche** :
- Tableau avec colonnes enrichies (timestamp, durÃ©e, actions)
- Bouton "Speed" (icÃ´ne Speed) â†’ ouvre `QuickTagEditDialog`
- Bouton "OpenInNew" â†’ ouvre l'appel complet au timestamp exact
- Coloration rouge/vert selon correct/incorrect

**Usage Level 0** : UtilisÃ© automatiquement par `ResultsPanel`

### 5. ConfusionMatrixPanel (matrice de confusion)

**Localisation** : `src/features/phase3-analysis/level1-validation/ui/components/AlgorithmLab/ConfusionMatrixPanel.tsx`

**Props** :
```typescript
interface ConfusionMatrixPanelProps {
  metrics: ClassificationMetrics;  // Contient confusionMatrix
}
```

**Ce qu'il affiche** :
- Matrice de confusion avec heatmap
- Lignes = Gold (annotation manuelle)
- Colonnes = Predicted (annotation LLM)
- Diagonale = accords, hors diagonale = dÃ©saccords

**Usage Level 0** :
```typescript
<ConfusionMatrixPanel metrics={level0Metrics} />
```

### 6. ErrorAnalysisPanel (analyse erreurs)

**Localisation** : `src/features/phase3-analysis/level1-validation/ui/components/AlgorithmLab/ErrorAnalysisPanel.tsx`

**Props** :
```typescript
interface ErrorAnalysisPanelProps {
  errorAnalysis?: {
    totalErrors: number;
    errorRate: number;
    errorsByCategory: Record<string, number>;
    // ...
  };
}
```

**Ce qu'il affiche** :
- Nombre total d'erreurs
- Distribution par catÃ©gorie (tag)
- Graphique des erreurs frÃ©quentes

**Usage Level 0** :
```typescript
<ErrorAnalysisPanel errorAnalysis={level0ErrorAnalysis} />
```

---

## ğŸ”„ Architecture simplifiÃ©e pour Level 0

### Workflow d'affichage

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    LEVEL 0 INTERFACE                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚  1ï¸âƒ£ Onglet "Contre-Annotation OpenAI"                              â”‚
â”‚     â€¢ Bouton "Lancer contre-annotation" (901 paires)               â”‚
â”‚     â€¢ Barre de progression (0/901)                                  â”‚
â”‚     â€¢ Sauvegarde rÃ©sultats en mÃ©moire                              â”‚
â”‚                                                                     â”‚
â”‚  2ï¸âƒ£ Onglet "Comparaison X (StratÃ©gie)"                             â”‚
â”‚     â€¢ <ResultsPanel> avec results adaptÃ©s                          â”‚
â”‚     â€¢ Filtrage : Tous / Accords / DÃ©saccords                       â”‚
â”‚     â€¢ Clic ligne â†’ <AnalysisPairContext> + dÃ©tails                 â”‚
â”‚                                                                     â”‚
â”‚  3ï¸âƒ£ Onglet "Comparaison Y (RÃ©action)"                              â”‚
â”‚     â€¢ <ResultsPanel> avec results adaptÃ©s                          â”‚
â”‚     â€¢ Filtrage : Tous / Accords / DÃ©saccords                       â”‚
â”‚     â€¢ Clic ligne â†’ <AnalysisPairContext> + dÃ©tails                 â”‚
â”‚                                                                     â”‚
â”‚  4ï¸âƒ£ Onglet "MÃ©triques Kappa"                                        â”‚
â”‚     â€¢ <ConfusionMatrixPanel> pour X et Y                           â”‚
â”‚     â€¢ Affichage Kappa, Po, Pe                                       â”‚
â”‚     â€¢ <ErrorAnalysisPanel> pour dÃ©saccords                         â”‚
â”‚                                                                     â”‚
â”‚  5ï¸âƒ£ Onglet "RÃ©solution DÃ©saccords"                                 â”‚
â”‚     â€¢ Liste filtrÃ©e : UNIQUEMENT les dÃ©saccords                    â”‚
â”‚     â€¢ Pour chaque dÃ©saccord :                                       â”‚
â”‚       - <AnalysisPairContext pairId={...} />                       â”‚
â”‚       - Bouton "RÃ©soudre" â†’ <QuickTagEditDialog>                   â”‚
â”‚       - Choix : Garder manuel / Adopter LLM / Autre               â”‚
â”‚                                                                     â”‚
â”‚  6ï¸âƒ£ Onglet "Validation Finale"                                      â”‚
â”‚     â€¢ RÃ©sumÃ© : X paires validÃ©es, Y dÃ©saccords restants           â”‚
â”‚     â€¢ Bouton "Appliquer Consensus" (remplir level0_gold_*)        â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ› ï¸ Adaptateur de donnÃ©es

### Transformation OpenAI â†’ TVValidationResultCore

**Fichier Ã  crÃ©er** : `src/features/phase3-analysis/level0-gold/domain/adapters/Level0ToTVAdapter.ts`

```typescript
import type { TVValidationResultCore } from '@/types/algorithm-lab';
import type { OpenAIAnnotationResult } from '../services/OpenAIAnnotatorService';

export class Level0ToTVAdapter {
  /**
   * Convertit les rÃ©sultats de contre-annotation OpenAI
   * en format compatible avec les composants Level 1
   */
  static adaptXResults(
    pairs: AnalysisPair[],
    openaiResults: OpenAIAnnotationResult[]
  ): TVValidationResultCore[] {
    return pairs.map((pair, index) => {
      const openaiResult = openaiResults[index];
      const manualTag = pair.strategy_tag;  // Annotation manuelle
      const llmTag = openaiResult.x_predicted;  // Annotation LLM
      
      return {
        verbatim: pair.conseiller_verbatim,
        goldStandard: manualTag,  // Gold = annotation manuelle
        predicted: llmTag,         // Predicted = annotation LLM
        confidence: openaiResult.x_confidence,
        correct: manualTag === llmTag,  // Accord ?
        metadata: {
          pairId: pair.pair_id,
          turnId: pair.conseiller_turn_id,
          callId: pair.call_id,
          start: pair.start_time,
          end: pair.end_time,
          prev1_turn_verbatim: pair.prev1_turn_verbatim,
          next1_turn_verbatim: pair.next1_turn_verbatim,
          prev2_turn_verbatim: pair.prev2_turn_verbatim,
          next2_turn_verbatim: pair.next2_turn_verbatim,
          prev3_turn_verbatim: pair.prev3_turn_verbatim,
          next3_turn_verbatim: pair.next3_turn_verbatim,
          client_verbatim: pair.client_verbatim,
          // MÃ©tadonnÃ©es Level 0
          llm_reasoning: openaiResult.x_reasoning,
          annotator1: 'Manuel',
          annotator2: 'OpenAI GPT-4',
        },
      };
    });
  }
  
  static adaptYResults(
    pairs: AnalysisPair[],
    openaiResults: OpenAIAnnotationResult[]
  ): TVValidationResultCore[] {
    return pairs.map((pair, index) => {
      const openaiResult = openaiResults[index];
      const manualTag = pair.reaction_tag;
      const llmTag = openaiResult.y_predicted;
      
      return {
        verbatim: pair.client_verbatim,
        goldStandard: manualTag,
        predicted: llmTag,
        confidence: openaiResult.y_confidence,
        correct: manualTag === llmTag,
        metadata: {
          pairId: pair.pair_id,
          turnId: pair.client_turn_id,
          callId: pair.call_id,
          start: pair.start_time,
          end: pair.end_time,
          prev1_turn_verbatim: pair.conseiller_verbatim,  // Pour Y, prev = conseiller
          next1_turn_verbatim: pair.next1_turn_verbatim,
          conseiller_verbatim: pair.conseiller_verbatim,
          llm_reasoning: openaiResult.y_reasoning,
          annotator1: 'Manuel',
          annotator2: 'OpenAI GPT-4',
        },
      };
    });
  }
  
  /**
   * Filtre uniquement les dÃ©saccords pour rÃ©solution
   */
  static getDisagreements(results: TVValidationResultCore[]): TVValidationResultCore[] {
    return results.filter(r => !r.correct);
  }
  
  /**
   * Calcule les mÃ©triques pour ConfusionMatrixPanel
   */
  static calculateMetrics(results: TVValidationResultCore[]): ClassificationMetrics {
    const total = results.length;
    const correct = results.filter(r => r.correct).length;
    const accuracy = correct / total;
    
    // Matrice de confusion
    const confusionMatrix: Record<string, Record<string, number>> = {};
    results.forEach(r => {
      if (!confusionMatrix[r.goldStandard]) confusionMatrix[r.goldStandard] = {};
      if (!confusionMatrix[r.goldStandard][r.predicted]) {
        confusionMatrix[r.goldStandard][r.predicted] = 0;
      }
      confusionMatrix[r.goldStandard][r.predicted]++;
    });
    
    // Calculer precision, recall, F1 par tag
    const tags = [...new Set([...results.map(r => r.goldStandard), ...results.map(r => r.predicted)])];
    const precision: Record<string, number> = {};
    const recall: Record<string, number> = {};
    const f1Score: Record<string, number> = {};
    
    tags.forEach(tag => {
      const tp = confusionMatrix[tag]?.[tag] || 0;
      const fp = Object.keys(confusionMatrix).reduce((sum, goldTag) => {
        return goldTag !== tag ? sum + (confusionMatrix[goldTag][tag] || 0) : sum;
      }, 0);
      const fn = Object.keys(confusionMatrix[tag] || {}).reduce((sum, predTag) => {
        return predTag !== tag ? sum + confusionMatrix[tag][predTag] : sum;
      }, 0);
      
      precision[tag] = tp / (tp + fp) || 0;
      recall[tag] = tp / (tp + fn) || 0;
      f1Score[tag] = 2 * (precision[tag] * recall[tag]) / (precision[tag] + recall[tag]) || 0;
    });
    
    return {
      accuracy,
      precision,
      recall,
      f1Score,
      confusionMatrix,
      avgProcessingTime: 0,  // Non applicable pour Level 0
      avgConfidence: results.reduce((sum, r) => sum + (r.confidence || 0), 0) / total,
    };
  }
}
```

---

## ğŸ“‹ Composants Level 0 simplifiÃ©s

### Level0Interface.tsx (orchestrateur)

```typescript
import React, { useState } from 'react';
import { Box, Tabs, Tab, Typography } from '@mui/material';
import { ResultsPanel } from '@/features/phase3-analysis/level1-validation/ui/components/AlgorithmLab/ResultsSample/ResultsPanel';
import { ConfusionMatrixPanel } from '@/features/phase3-analysis/level1-validation/ui/components/AlgorithmLab/ConfusionMatrixPanel';
import { ErrorAnalysisPanel } from '@/features/phase3-analysis/level1-validation/ui/components/AlgorithmLab/ErrorAnalysisPanel';
import { AnnotationLauncher } from './AnnotationLauncher';
import { DisagreementResolver } from './DisagreementResolver';
import { GoldStandardValidator } from './GoldStandardValidator';

import { Level0ToTVAdapter } from '../../domain/adapters/Level0ToTVAdapter';
import { OpenAIAnnotatorService } from '../../domain/services/OpenAIAnnotatorService';
import { KappaCalculationService } from '../../domain/services/KappaCalculationService';

export const Level0Interface: React.FC = () => {
  const [currentTab, setCurrentTab] = useState(0);
  const [openaiResults, setOpenaiResults] = useState<OpenAIAnnotationResult[]>([]);
  const [analysisPairs, setAnalysisPairs] = useState<AnalysisPair[]>([]);
  
  // Adapter les rÃ©sultats pour les composants Level 1
  const xResults = Level0ToTVAdapter.adaptXResults(analysisPairs, openaiResults);
  const yResults = Level0ToTVAdapter.adaptYResults(analysisPairs, openaiResults);
  
  const xMetrics = Level0ToTVAdapter.calculateMetrics(xResults);
  const yMetrics = Level0ToTVAdapter.calculateMetrics(yResults);
  
  const xDisagreements = Level0ToTVAdapter.getDisagreements(xResults);
  const yDisagreements = Level0ToTVAdapter.getDisagreements(yResults);
  
  const handleAnnotationComplete = (results: OpenAIAnnotationResult[]) => {
    setOpenaiResults(results);
  };
  
  return (
    <Box>
      <Typography variant="h4">Level 0: Gold Standard - Contre-Annotation LLM</Typography>
      
      <Tabs value={currentTab} onChange={(e, v) => setCurrentTab(v)}>
        <Tab label="1. Lancer Annotation" />
        <Tab label="2. Comparaison X" disabled={!openaiResults.length} />
        <Tab label="3. Comparaison Y" disabled={!openaiResults.length} />
        <Tab label="4. MÃ©triques Kappa" disabled={!openaiResults.length} />
        <Tab label="5. RÃ©solution" disabled={!xDisagreements.length && !yDisagreements.length} />
        <Tab label="6. Validation" />
      </Tabs>
      
      {/* Onglet 1: Lancement */}
      {currentTab === 0 && (
        <AnnotationLauncher onComplete={handleAnnotationComplete} />
      )}
      
      {/* Onglet 2: Comparaison X */}
      {currentTab === 1 && (
        <Box mt={2}>
          <Typography variant="h6">Comparaison Variable X (StratÃ©gie Conseiller)</Typography>
          <Typography variant="body2" color="text.secondary" mb={2}>
            Gold = Annotation manuelle | Predicted = OpenAI GPT-4
          </Typography>
          <ResultsPanel
            results={xResults}
            initialPageSize={20}
            targetKind="X"
            classifierLabel="OpenAI GPT-4 (Annotateur 2)"
          />
        </Box>
      )}
      
      {/* Onglet 3: Comparaison Y */}
      {currentTab === 2 && (
        <Box mt={2}>
          <Typography variant="h6">Comparaison Variable Y (RÃ©action Client)</Typography>
          <Typography variant="body2" color="text.secondary" mb={2}>
            Gold = Annotation manuelle | Predicted = OpenAI GPT-4
          </Typography>
          <ResultsPanel
            results={yResults}
            initialPageSize={20}
            targetKind="Y"
            classifierLabel="OpenAI GPT-4 (Annotateur 2)"
          />
        </Box>
      )}
      
      {/* Onglet 4: MÃ©triques */}
      {currentTab === 3 && (
        <Box mt={2}>
          <Typography variant="h6" mb={2}>MÃ©triques Cohen's Kappa</Typography>
          
          <Box mb={4}>
            <Typography variant="subtitle1">Variable X (StratÃ©gie)</Typography>
            <Typography>Kappa: {xMetrics.kappa?.toFixed(3)}</Typography>
            <Typography>Accuracy: {(xMetrics.accuracy * 100).toFixed(2)}%</Typography>
            <ConfusionMatrixPanel metrics={xMetrics} />
          </Box>
          
          <Box>
            <Typography variant="subtitle1">Variable Y (RÃ©action)</Typography>
            <Typography>Kappa: {yMetrics.kappa?.toFixed(3)}</Typography>
            <Typography>Accuracy: {(yMetrics.accuracy * 100).toFixed(2)}%</Typography>
            <ConfusionMatrixPanel metrics={yMetrics} />
          </Box>
        </Box>
      )}
      
      {/* Onglet 5: RÃ©solution */}
      {currentTab === 4 && (
        <DisagreementResolver
          xDisagreements={xDisagreements}
          yDisagreements={yDisagreements}
          onResolve={handleResolve}
        />
      )}
      
      {/* Onglet 6: Validation */}
      {currentTab === 5 && (
        <GoldStandardValidator
          totalPairs={analysisPairs.length}
          xDisagreements={xDisagreements.length}
          yDisagreements={yDisagreements.length}
          onValidate={handleFinalValidation}
        />
      )}
    </Box>
  );
};
```

### DisagreementResolver.tsx (rÃ©solution dÃ©saccords)

```typescript
import React, { useState } from 'react';
import { Box, Typography, Button, Stack } from '@mui/material';
import { AnalysisPairContext } from '@/features/shared/ui/components/AnalysisPairContext';
import { QuickTagEditDialog } from '@/features/phase3-analysis/level1-validation/ui/components/AlgorithmLab/ResultsSample/components/QuickTagEditDialog';

interface DisagreementResolverProps {
  xDisagreements: TVValidationResultCore[];
  yDisagreements: TVValidationResultCore[];
  onResolve: (pairId: number, variable: 'X' | 'Y', resolvedTag: string) => void;
}

export const DisagreementResolver: React.FC<DisagreementResolverProps> = ({
  xDisagreements,
  yDisagreements,
  onResolve,
}) => {
  const [editDialogOpen, setEditDialogOpen] = useState(false);
  const [currentDisagreement, setCurrentDisagreement] = useState<TVValidationResultCore | null>(null);
  const [currentVariable, setCurrentVariable] = useState<'X' | 'Y'>('X');
  
  const handleOpenEdit = (disagreement: TVValidationResultCore, variable: 'X' | 'Y') => {
    setCurrentDisagreement(disagreement);
    setCurrentVariable(variable);
    setEditDialogOpen(true);
  };
  
  const handleAdoptLLM = (disagreement: TVValidationResultCore, variable: 'X' | 'Y') => {
    onResolve(disagreement.metadata.pairId, variable, disagreement.predicted);
  };
  
  return (
    <Box mt={2}>
      <Typography variant="h6">RÃ©solution des DÃ©saccords</Typography>
      
      {/* DÃ©saccords X */}
      {xDisagreements.length > 0 && (
        <Box mb={4}>
          <Typography variant="subtitle1" color="primary" mb={2}>
            Variable X - {xDisagreements.length} dÃ©saccords
          </Typography>
          {xDisagreements.map((disagreement, index) => (
            <Box key={index} mb={3} p={2} border="1px solid #ddd" borderRadius={2}>
              {/* Affichage du contexte avec le composant rÃ©utilisable */}
              <AnalysisPairContext pairId={disagreement.metadata.pairId} />
              
              {/* Affichage des annotations */}
              <Stack direction="row" spacing={2} mt={2} alignItems="center">
                <Typography>
                  <strong>Annotation manuelle:</strong> {disagreement.goldStandard}
                </Typography>
                <Typography>
                  <strong>Annotation LLM:</strong> {disagreement.predicted} ({(disagreement.confidence * 100).toFixed(0)}%)
                </Typography>
              </Stack>
              
              {/* Raisonnement LLM */}
              {disagreement.metadata.llm_reasoning && (
                <Typography variant="body2" color="text.secondary" mt={1}>
                  <em>Raisonnement LLM:</em> {disagreement.metadata.llm_reasoning}
                </Typography>
              )}
              
              {/* Boutons de rÃ©solution */}
              <Stack direction="row" spacing={2} mt={2}>
                <Button variant="outlined" onClick={() => handleOpenEdit(disagreement, 'X')}>
                  Ã‰diter manuellement
                </Button>
                <Button variant="contained" onClick={() => handleAdoptLLM(disagreement, 'X')}>
                  Adopter suggestion LLM
                </Button>
                <Button variant="outlined" color="secondary">
                  Marquer comme ambiguÃ«
                </Button>
              </Stack>
            </Box>
          ))}
        </Box>
      )}
      
      {/* DÃ©saccords Y (mÃªme structure) */}
      {yDisagreements.length > 0 && (
        <Box>
          <Typography variant="subtitle1" color="primary" mb={2}>
            Variable Y - {yDisagreements.length} dÃ©saccords
          </Typography>
          {/* MÃªme structure que X */}
        </Box>
      )}
      
      {/* Dialog d'Ã©dition rÃ©utilisÃ© */}
      {currentDisagreement && (
        <QuickTagEditDialog
          open={editDialogOpen}
          onClose={() => setEditDialogOpen(false)}
          turnId={currentDisagreement.metadata.turnId}
          pairId={currentDisagreement.metadata.pairId}
          currentTag={currentDisagreement.goldStandard}
          speaker={currentVariable === 'X' ? 'conseiller' : 'client'}
          verbatim={currentDisagreement.verbatim}
          onSuccess={() => {
            setEditDialogOpen(false);
            // Callback pour refresh
          }}
        />
      )}
    </Box>
  );
};
```

---

## ğŸ“Š RÃ©sumÃ© des bÃ©nÃ©fices

| Composant rÃ©utilisÃ© | Gain | Effort Ã©conomisÃ© |
|---------------------|------|------------------|
| `ResultsPanel` | Affichage tableau complet avec pagination, filtres | ~4h dÃ©veloppement |
| `AnalysisPairContext` | Contexte prev3â†’next3, toggle, fetch auto | ~3h dÃ©veloppement |
| `QuickTagEditDialog` | Ã‰dition tags avec sync turntagged/analysis_pairs | ~2h dÃ©veloppement |
| `ConfusionMatrixPanel` | Matrice de confusion avec heatmap | ~2h dÃ©veloppement |
| `ErrorAnalysisPanel` | Analyse erreurs par catÃ©gorie | ~1h dÃ©veloppement |
| **TOTAL** | | **~12h Ã©conomisÃ©es** |

---

## âœ… Plan d'action rÃ©visÃ©

### Session 1 (2-3h) - Services mÃ©tier

- [ ] CrÃ©er `OpenAIAnnotatorService.ts`
- [ ] CrÃ©er `KappaCalculationService.ts`
- [ ] CrÃ©er `Level0ToTVAdapter.ts` â­ **CLÃ‰**
- [ ] Tester sur 10 paires Ã©chantillon

### Session 2 (2-3h) - Interface UI

- [ ] CrÃ©er `Level0Interface.tsx` (orchestrateur)
- [ ] CrÃ©er `AnnotationLauncher.tsx` (bouton + progress)
- [ ] CrÃ©er `DisagreementResolver.tsx` (rÃ©utilise composants)
- [ ] CrÃ©er `GoldStandardValidator.tsx` (bouton final)

### Session 3 (2h) - Annotation complÃ¨te

- [ ] Annoter 901 paires avec OpenAI
- [ ] Calculer Kappa
- [ ] Afficher dans `ResultsPanel` âœ…
- [ ] Identifier dÃ©saccords

### Session 4 (1-2h) - RÃ©solution et validation

- [ ] RÃ©soudre dÃ©saccords avec `QuickTagEditDialog` âœ…
- [ ] Appliquer consensus â†’ `level0_gold_*`
- [ ] VÃ©rifier cohÃ©rence

---

## ğŸ¯ Points clÃ©s Ã  retenir

1. **Ne PAS recrÃ©er** les composants d'affichage
2. **Adapter les donnÃ©es** avec `Level0ToTVAdapter`
3. **RÃ©utiliser** `ResultsPanel`, `AnalysisPairContext`, `QuickTagEditDialog`
4. **Focus sur** la logique mÃ©tier (OpenAI, Kappa)
5. **Ã‰conomie** : ~12h de dÃ©veloppement UI

---

*IntÃ©gration parfaite avec l'existant = mission plus rapide et code plus maintenable* âœ…
